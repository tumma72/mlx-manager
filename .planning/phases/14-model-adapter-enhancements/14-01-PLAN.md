---
phase: 14-model-adapter-enhancements
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/mlx_manager/mlx_server/schemas/openai.py
  - backend/mlx_manager/mlx_server/models/adapters/base.py
autonomous: true

must_haves:
  truths:
    - "Tool/function schemas can be imported and instantiated"
    - "ModelAdapter protocol includes tool calling, reasoning, and message conversion methods"
    - "Default implementations return appropriate defaults (False, None, unchanged messages)"
  artifacts:
    - path: "backend/mlx_manager/mlx_server/schemas/openai.py"
      provides: "Tool calling schemas (FunctionDefinition, Tool, ToolCall, FunctionCall)"
      contains: "class ToolCall"
    - path: "backend/mlx_manager/mlx_server/models/adapters/base.py"
      provides: "Extended ModelAdapter protocol with optional methods"
      contains: "supports_tool_calling"
  key_links:
    - from: "adapters/base.py"
      to: "schemas/openai.py"
      via: "ToolCall type reference"
      pattern: "ToolCall"
---

<objective>
Add OpenAI-compatible tool calling schemas and extend the ModelAdapter protocol with optional methods for tool calling, reasoning extraction, and message conversion.

Purpose: Establish the foundation types and interfaces that all subsequent plans (tool parsers, reasoning extraction, structured output) will build upon.

Output: Extended schemas/openai.py with tool calling types, and extended adapters/base.py with new protocol methods.
</objective>

<execution_context>
@.claude/get-shit-done/workflows/execute-plan.md
@.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-model-adapter-enhancements/14-RESEARCH.md
@backend/mlx_manager/mlx_server/schemas/openai.py
@backend/mlx_manager/mlx_server/models/adapters/base.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Tool Calling Schemas to openai.py</name>
  <files>backend/mlx_manager/mlx_server/schemas/openai.py</files>
  <action>
Add the following Pydantic models to schemas/openai.py:

1. FunctionDefinition - function name, description, parameters (JSON Schema dict)
2. Tool - type="function" + FunctionDefinition
3. FunctionCall - name + arguments (JSON string)
4. ToolCall - id, type="function", function (FunctionCall)
5. ResponseFormat - type (text|json_object|json_schema) + optional json_schema dict
6. ToolChoiceOption - Union type for "none"|"auto"|"required"|dict

Update ChatCompletionRequest to add optional fields:
- tools: list[Tool] | None = None
- tool_choice: ToolChoiceOption | None = None
- response_format: ResponseFormat | None = None

Update ChatMessage to support tool calls:
- tool_calls: list[ToolCall] | None = None (for assistant messages)
- tool_call_id: str | None = None (for tool response messages)
- Add "tool" to role Literal

Update ChatCompletionChoice to include tool_calls:
- tool_calls: list[ToolCall] | None = None
- Add "tool_calls" to finish_reason Literal

Reference: OpenAI API spec and 14-RESEARCH.md Example 3
  </action>
  <verify>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
python -c "from mlx_manager.mlx_server.schemas.openai import Tool, ToolCall, FunctionCall, FunctionDefinition, ResponseFormat; print('Schemas imported successfully')"
```
  </verify>
  <done>
Tool calling schemas (Tool, ToolCall, FunctionCall, FunctionDefinition, ResponseFormat) exist and can be imported. ChatCompletionRequest supports tools, tool_choice, and response_format fields.
  </done>
</task>

<task type="auto">
  <name>Task 2: Extend ModelAdapter Protocol</name>
  <files>backend/mlx_manager/mlx_server/models/adapters/base.py</files>
  <action>
Extend the ModelAdapter protocol with new optional methods. Add these methods to the Protocol class with default implementations that can be overridden:

1. supports_tool_calling(self) -> bool
   - Returns False by default
   - Indicates if model family supports tool calling

2. parse_tool_calls(self, text: str) -> list[dict] | None
   - Returns None by default
   - Parses tool calls from model output text
   - Return format: list of {"id": str, "type": "function", "function": {"name": str, "arguments": str}}

3. format_tools_for_prompt(self, tools: list[dict]) -> str
   - Returns "" by default
   - Formats tool definitions for inclusion in system prompt

4. get_tool_call_stop_tokens(self, tokenizer: Any) -> list[int]
   - Returns [] by default
   - Returns additional stop tokens to use when tools are enabled

5. supports_reasoning_mode(self) -> bool
   - Returns False by default
   - Indicates if model supports thinking/reasoning output

6. extract_reasoning(self, text: str) -> tuple[str | None, str]
   - Returns (None, text) by default
   - Extracts reasoning content from response
   - Returns (reasoning_content, final_content)

7. convert_messages(self, messages: list[dict]) -> list[dict]
   - Returns messages unchanged by default
   - Converts OpenAI-format messages to model-specific format

Update DefaultAdapter class to implement all new methods with the default behaviors.

NOTE: These are optional methods with sensible defaults. Specific adapters will override only what they support.
  </action>
  <verify>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
python -c "
from mlx_manager.mlx_server.models.adapters.base import DefaultAdapter, ModelAdapter
adapter = DefaultAdapter()
assert adapter.supports_tool_calling() == False
assert adapter.parse_tool_calls('test') == None
assert adapter.format_tools_for_prompt([]) == ''
assert adapter.get_tool_call_stop_tokens(None) == []
assert adapter.supports_reasoning_mode() == False
assert adapter.extract_reasoning('hello') == (None, 'hello')
assert adapter.convert_messages([{'role': 'user'}]) == [{'role': 'user'}]
print('All protocol methods work correctly')
"
```
  </verify>
  <done>
ModelAdapter protocol extended with 7 new optional methods. DefaultAdapter implements all methods with appropriate default behaviors.
  </done>
</task>

<task type="auto">
  <name>Task 3: Run Quality Checks</name>
  <files>backend/mlx_manager/mlx_server/schemas/openai.py, backend/mlx_manager/mlx_server/models/adapters/base.py</files>
  <action>
Run linting, formatting, and type checking to ensure code quality:

1. Run ruff check with auto-fix
2. Run ruff format
3. Run mypy on the modified files

Fix any issues that arise.
  </action>
  <verify>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
ruff check mlx_manager/mlx_server/schemas/openai.py mlx_manager/mlx_server/models/adapters/base.py && \
ruff format --check mlx_manager/mlx_server/schemas/openai.py mlx_manager/mlx_server/models/adapters/base.py && \
mypy mlx_manager/mlx_server/schemas/openai.py mlx_manager/mlx_server/models/adapters/base.py
```
  </verify>
  <done>
All quality checks pass (ruff check, ruff format, mypy) for modified files.
  </done>
</task>

</tasks>

<verification>
- [ ] Tool calling schemas importable: `from mlx_manager.mlx_server.schemas.openai import Tool, ToolCall, FunctionCall`
- [ ] ChatCompletionRequest has tools, tool_choice, response_format fields
- [ ] ModelAdapter protocol has 7 new methods
- [ ] DefaultAdapter implements all methods with defaults
- [ ] Quality gates pass (ruff, mypy)
</verification>

<success_criteria>
1. Tool, ToolCall, FunctionCall, FunctionDefinition, ResponseFormat schemas exist
2. ChatCompletionRequest supports tools, tool_choice, response_format
3. ChatMessage supports tool_calls and tool_call_id
4. ModelAdapter protocol defines 7 new optional methods
5. DefaultAdapter provides sensible default implementations
6. All quality checks pass
</success_criteria>

<output>
After completion, create `.planning/phases/14-model-adapter-enhancements/14-01-SUMMARY.md`
</output>
