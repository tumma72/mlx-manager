---
phase: 14-model-adapter-enhancements
plan: 05
type: execute
wave: 2
depends_on: ["14-01"]
files_modified:
  - backend/mlx_manager/mlx_server/models/pool.py
  - backend/mlx_manager/mlx_server/models/types.py
autonomous: true

must_haves:
  truths:
    - "Model pool can load a model with LoRA adapter"
    - "Adapter path is validated before loading"
    - "LoadedModel tracks adapter_path when loaded with adapter"
    - "Model pool status shows adapter info"
  artifacts:
    - path: "backend/mlx_manager/mlx_server/models/pool.py"
      provides: "Extended model pool with adapter loading"
      contains: "adapter_path"
    - path: "backend/mlx_manager/mlx_server/models/types.py"
      provides: "AdapterInfo type"
      contains: "AdapterInfo"
  key_links:
    - from: "models/pool.py"
      to: "mlx_lm.load"
      via: "adapter_path parameter"
      pattern: "load.*adapter_path"
---

<objective>
Extend the model pool manager to support loading LoRA adapters alongside base models.

Purpose: LoRA adapters allow fine-tuned behavior without full model retraining. Users should be able to load a base model with an optional adapter for specialized tasks.

Output: Extended ModelPoolManager with adapter loading support and AdapterInfo type.
</objective>

<execution_context>
@.claude/get-shit-done/workflows/execute-plan.md
@.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/14-model-adapter-enhancements/14-RESEARCH.md
@backend/mlx_manager/mlx_server/models/pool.py
@backend/mlx_manager/mlx_server/models/types.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add AdapterInfo Type and Extend LoadedModel</name>
  <files>
backend/mlx_manager/mlx_server/models/types.py
backend/mlx_manager/mlx_server/models/pool.py
  </files>
  <action>
1. In types.py, add AdapterInfo dataclass:
```python
@dataclass
class AdapterInfo:
    """Information about a loaded LoRA adapter."""
    adapter_path: str
    base_model: str | None = None  # From adapter_config.json if available
    description: str | None = None
```

2. In pool.py, extend LoadedModel dataclass:
   - Add adapter_path: str | None = None field
   - Add adapter_info: AdapterInfo | None = None field

3. Update get_status() in ModelPoolManager to include adapter info in loaded_models response.
  </action>
  <verify>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
python -c "
from mlx_manager.mlx_server.models.types import AdapterInfo

info = AdapterInfo(adapter_path='/path/to/adapter', base_model='llama-3b')
print(f'AdapterInfo: {info}')

from mlx_manager.mlx_server.models.pool import LoadedModel
import time
loaded = LoadedModel(
    model_id='test',
    model=None,
    tokenizer=None,
    adapter_path='/path/to/adapter'
)
assert loaded.adapter_path == '/path/to/adapter'
print('LoadedModel supports adapter_path')
"
```
  </verify>
  <done>
AdapterInfo type exists. LoadedModel has adapter_path and adapter_info fields.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add Adapter Loading Support to ModelPoolManager</name>
  <files>backend/mlx_manager/mlx_server/models/pool.py</files>
  <action>
Extend ModelPoolManager with adapter loading capabilities:

1. Add _validate_adapter_path(adapter_path: str) -> AdapterInfo method:
   - Check adapter_path is a directory
   - Check adapter_config.json exists in the directory
   - Parse adapter_config.json to get base_model info
   - Return AdapterInfo with parsed data
   - Raise ValueError with helpful message if validation fails
   Reference: 14-RESEARCH.md Pitfall 5

2. Add get_model_with_adapter(model_id: str, adapter_path: str) -> LoadedModel method:
   - Validate adapter_path first
   - Create cache key combining model_id and adapter_path (e.g., f"{model_id}::{adapter_path}")
   - Check if model+adapter combo is already loaded
   - If not loaded, call _load_model_with_adapter()
   - Return LoadedModel with adapter_path and adapter_info set

3. Add _load_model_with_adapter() private method:
   - Similar to _load_model() but passes adapter_path to mlx_lm.load()
   - Only support TEXT_GEN models with adapters initially
   - Vision and embedding models don't support LoRA in mlx-vlm/mlx-embeddings yet

4. Update get_status() to include adapter info in response.

Note: Models with adapters use a composite cache key. The same base model can be loaded multiple times with different adapters.
  </action>
  <verify>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
python -c "
from mlx_manager.mlx_server.models.pool import ModelPoolManager

pool = ModelPoolManager()

# Test validation method exists
try:
    pool._validate_adapter_path('/nonexistent/path')
except ValueError as e:
    assert 'directory' in str(e).lower() or 'exist' in str(e).lower()
    print('Validation correctly rejects invalid paths')

# Check method exists
assert hasattr(pool, 'get_model_with_adapter')
print('get_model_with_adapter method exists')
"
```
  </verify>
  <done>
ModelPoolManager has _validate_adapter_path() and get_model_with_adapter() methods. Adapter path validation checks for directory and adapter_config.json.
  </done>
</task>

<task type="auto">
  <name>Task 3: Run Quality Checks</name>
  <files>
backend/mlx_manager/mlx_server/models/pool.py
backend/mlx_manager/mlx_server/models/types.py
  </files>
  <action>
Run quality checks on modified files:

1. ruff check with auto-fix
2. ruff format
3. mypy on modified files

Fix any issues that arise.
  </action>
  <verify>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
ruff check mlx_manager/mlx_server/models/pool.py mlx_manager/mlx_server/models/types.py --fix && \
ruff format mlx_manager/mlx_server/models/pool.py mlx_manager/mlx_server/models/types.py && \
mypy mlx_manager/mlx_server/models/pool.py mlx_manager/mlx_server/models/types.py
```
  </verify>
  <done>
All quality checks pass for modified model files.
  </done>
</task>

</tasks>

<verification>
- [ ] AdapterInfo dataclass exists in types.py
- [ ] LoadedModel has adapter_path and adapter_info fields
- [ ] _validate_adapter_path() validates directory and config file
- [ ] get_model_with_adapter() method exists on ModelPoolManager
- [ ] Model+adapter uses composite cache key
- [ ] get_status() includes adapter info
- [ ] Quality gates pass (ruff, mypy)
</verification>

<success_criteria>
1. AdapterInfo type captures adapter metadata
2. LoadedModel tracks adapter_path
3. Adapter path validation checks for adapter_config.json
4. Models can be loaded with LoRA adapters
5. Same base model can have multiple adapters loaded
6. All quality checks pass
</success_criteria>

<output>
After completion, create `.planning/phases/14-model-adapter-enhancements/14-05-SUMMARY.md`
</output>
