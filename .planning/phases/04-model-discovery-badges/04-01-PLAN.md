---
phase: 04-model-discovery-badges
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/mlx_manager/types.py
  - backend/mlx_manager/utils/model_detection.py
  - backend/mlx_manager/routers/models.py
  - backend/mlx_manager/services/hf_client.py
  - backend/mlx_manager/models.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "API returns model characteristics for local models"
    - "API returns model characteristics for remote HuggingFace models"
    - "Architecture family is normalized (Llama, Qwen, Mistral, etc.)"
    - "Multimodal capability is detected from vision_config or model_type"
    - "Quantization bits are extracted from config"
  artifacts:
    - path: "backend/mlx_manager/types.py"
      provides: "ModelCharacteristics TypedDict"
      contains: "class ModelCharacteristics"
    - path: "backend/mlx_manager/utils/model_detection.py"
      provides: "extract_characteristics function"
      contains: "def extract_characteristics"
    - path: "backend/mlx_manager/routers/models.py"
      provides: "GET /api/models/config/{model_id} endpoint"
      contains: "/config/{model_id:path}"
  key_links:
    - from: "routers/models.py"
      to: "utils/model_detection.py"
      via: "extract_characteristics call"
      pattern: "extract_characteristics"
    - from: "models.py (LocalModel)"
      to: "ModelCharacteristics"
      via: "characteristics field"
      pattern: "characteristics.*ModelCharacteristics"
---

<objective>
Add backend support for extracting and serving model characteristics from config.json files.

Purpose: Enable frontend to display model badges and specs by providing structured metadata about architecture, multimodal capabilities, context window, and quantization.

Output: New API endpoint `/api/models/config/{model_id}` that returns ModelCharacteristics, plus updated `/api/models/local` that includes characteristics for each model.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-model-discovery-badges/04-CONTEXT.md
@.planning/phases/04-model-discovery-badges/04-RESEARCH.md

@backend/mlx_manager/types.py
@backend/mlx_manager/utils/model_detection.py
@backend/mlx_manager/routers/models.py
@backend/mlx_manager/services/hf_api.py
@backend/mlx_manager/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add ModelCharacteristics type and extraction logic</name>
  <files>
    backend/mlx_manager/types.py
    backend/mlx_manager/utils/model_detection.py
  </files>
  <action>
    1. In types.py, add ModelCharacteristics TypedDict with total=False:
       - model_type: str (raw from config)
       - architecture_family: str (normalized: "Llama", "Qwen", "Mistral", etc.)
       - max_position_embeddings: int (context window)
       - num_hidden_layers: int
       - hidden_size: int
       - vocab_size: int
       - num_attention_heads: int
       - num_key_value_heads: int | None (GQA heads)
       - quantization_bits: int | None (2, 3, 4, 8, or None for fp16/bf16)
       - quantization_group_size: int | None
       - is_multimodal: bool
       - multimodal_type: str | None ("vision" or None)
       - use_cache: bool (KV cache enabled, default True)

    2. In model_detection.py, add:
       - ARCHITECTURE_FAMILIES dict mapping model_type patterns to display names
         (llama -> "Llama", qwen2 -> "Qwen", mistral -> "Mistral", gemma2 -> "Gemma",
          phi3 -> "Phi", mllama -> "Llama", starcoder2 -> "StarCoder", deepseek -> "DeepSeek",
          glm -> "GLM", minimax -> "MiniMax")

       - detect_multimodal(config: dict) -> tuple[bool, str | None]:
         Check for vision_config key, image_token_id/video_token_id keys,
         or "vl"/"vision"/"multimodal" in model_type/architectures.
         Return (is_multimodal, multimodal_type)

       - normalize_architecture(config: dict) -> str:
         Extract model_type, match against ARCHITECTURE_FAMILIES (partial match too).
         Fallback to architectures[0] field. Return "Unknown" if no match.

       - extract_characteristics(config: dict) -> ModelCharacteristics:
         Build ModelCharacteristics from config dict.
         Handle missing fields gracefully (use .get() with defaults).
         Call detect_multimodal and normalize_architecture.
         Extract quantization from config.get("quantization", {}).get("bits")

       - extract_characteristics_from_model(model_id: str) -> ModelCharacteristics | None:
         Call read_model_config(model_id), if exists call extract_characteristics.
         Return None if model not downloaded or no config.json.
  </action>
  <verify>
    cd backend && python -c "
from mlx_manager.types import ModelCharacteristics
from mlx_manager.utils.model_detection import extract_characteristics, detect_multimodal, normalize_architecture

# Test with sample config
config = {
    'model_type': 'qwen2',
    'architectures': ['Qwen2ForCausalLM'],
    'max_position_embeddings': 32768,
    'num_hidden_layers': 28,
    'hidden_size': 3584,
    'vocab_size': 152064,
    'num_attention_heads': 28,
    'num_key_value_heads': 4,
    'quantization': {'bits': 4, 'group_size': 64}
}
chars = extract_characteristics(config)
assert chars['architecture_family'] == 'Qwen'
assert chars['quantization_bits'] == 4
assert chars['is_multimodal'] == False
print('Extraction works!')

# Test multimodal detection
vision_config = {'model_type': 'qwen2_vl', 'vision_config': {}}
is_mm, mm_type = detect_multimodal(vision_config)
assert is_mm == True
assert mm_type == 'vision'
print('Multimodal detection works!')
"
  </verify>
  <done>
    - ModelCharacteristics type exists in types.py
    - extract_characteristics() extracts all fields from config dict
    - detect_multimodal() correctly identifies vision models
    - normalize_architecture() maps model types to family names
  </done>
</task>

<task type="auto">
  <name>Task 2: Add config endpoint and update local models response</name>
  <files>
    backend/mlx_manager/routers/models.py
    backend/mlx_manager/services/hf_api.py
    backend/mlx_manager/models.py
  </files>
  <action>
    1. In hf_api.py, add async function fetch_remote_config(model_id: str) -> dict | None:
       - URL: f"https://huggingface.co/{model_id}/resolve/main/config.json"
       - Use httpx.AsyncClient with timeout=10.0
       - Return parsed JSON on 200, None on error (log warning)

    2. In routers/models.py, add new endpoint:
       ```python
       @router.get("/config/{model_id:path}")
       async def get_model_config(
           current_user: Annotated[User, Depends(get_current_user)],
           model_id: str,
       ):
           """Get model characteristics from config.json.

           For local models: reads from HuggingFace cache.
           For remote models: fetches via HuggingFace resolve API.
           """
           from mlx_manager.utils.model_detection import (
               extract_characteristics_from_model,
               extract_characteristics,
           )
           from mlx_manager.services.hf_api import fetch_remote_config

           # Try local first
           chars = extract_characteristics_from_model(model_id)
           if chars:
               return chars

           # Fetch remote
           config = await fetch_remote_config(model_id)
           if config:
               return extract_characteristics(config)

           raise HTTPException(status_code=404, detail="Config not found")
       ```

    3. In models.py, update LocalModel class to include optional characteristics:
       - Add field: characteristics: ModelCharacteristics | None = None

    4. In routers/models.py, update list_local_models to populate characteristics:
       - For each LocalModel, call extract_characteristics_from_model
       - Include characteristics in response (None if unavailable)

    5. In hf_client.py list_local_models(), update to include characteristics:
       - Import and call extract_characteristics_from_model for each model
       - Add to LocalModelInfo dict or model object
  </action>
  <verify>
    # Start backend and test endpoints
    cd backend && source .venv/bin/activate && uvicorn mlx_manager.main:app --port 8080 &
    sleep 3

    # Test config endpoint with a known model (adjust model_id based on what's downloaded)
    # This will work for remote models even if not downloaded locally
    curl -s http://localhost:8080/api/models/config/mlx-community/Qwen2.5-0.5B-Instruct-4bit \
      -H "Authorization: Bearer $(cat /tmp/test_token 2>/dev/null || echo 'test')" | head -c 500

    # Test local models endpoint includes characteristics
    curl -s http://localhost:8080/api/models/local \
      -H "Authorization: Bearer $(cat /tmp/test_token 2>/dev/null || echo 'test')" | head -c 500

    # Kill background server
    pkill -f "uvicorn mlx_manager.main:app" 2>/dev/null || true
  </verify>
  <done>
    - GET /api/models/config/{model_id} returns ModelCharacteristics
    - Endpoint works for both local (cache read) and remote (HF API) models
    - GET /api/models/local includes characteristics for each downloaded model
    - 404 returned when config cannot be found for model
  </done>
</task>

<task type="auto">
  <name>Task 3: Add tests for characteristics extraction</name>
  <files>
    backend/tests/test_model_detection.py
  </files>
  <action>
    Create or update backend/tests/test_model_detection.py with tests:

    1. Test extract_characteristics with complete config:
       - Verify all fields extracted correctly
       - Verify architecture_family normalization

    2. Test extract_characteristics with minimal config:
       - Only model_type present
       - Verify missing fields handled gracefully (None or defaults)

    3. Test detect_multimodal:
       - Config with vision_config -> (True, "vision")
       - Config with image_token_id -> (True, "vision")
       - Config with model_type containing "vl" -> (True, "vision")
       - Text-only config -> (False, None)

    4. Test normalize_architecture:
       - "qwen2" -> "Qwen"
       - "llama" -> "Llama"
       - "unknown_model" -> "Unknown"

    5. Test quantization extraction:
       - Config with quantization.bits=4 -> quantization_bits=4
       - Config without quantization -> quantization_bits=None

    Run: cd backend && pytest tests/test_model_detection.py -v
  </action>
  <verify>
    cd backend && source .venv/bin/activate && pytest tests/test_model_detection.py -v
  </verify>
  <done>
    - All tests pass
    - Edge cases covered (missing fields, unknown architectures)
    - Multimodal detection tested for all signal types
  </done>
</task>

</tasks>

<verification>
1. Run full backend test suite: `cd backend && pytest -v`
2. Verify type checking passes: `cd backend && mypy mlx_manager`
3. Verify linting passes: `cd backend && ruff check . && ruff format --check .`
</verification>

<success_criteria>
- ModelCharacteristics type defined with all required fields
- extract_characteristics() handles complete and partial configs
- GET /api/models/config/{model_id} works for local and remote models
- GET /api/models/local includes characteristics for downloaded models
- All tests pass, mypy clean, ruff clean
</success_criteria>

<output>
After completion, create `.planning/phases/04-model-discovery-badges/04-01-SUMMARY.md`
</output>
