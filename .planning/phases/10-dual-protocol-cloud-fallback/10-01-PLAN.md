---
phase: 10-dual-protocol-cloud-fallback
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/mlx_manager/mlx_server/schemas/anthropic.py
  - backend/tests/mlx_server/schemas/test_anthropic.py
autonomous: true

must_haves:
  truths:
    - "Anthropic request schema validates max_tokens as required field"
    - "Content blocks can be string or list of TextBlockParam/ImageBlockParam"
    - "System message is separate field, not in messages array"
    - "Response schema includes proper stop_reason enum values"
  artifacts:
    - path: "backend/mlx_manager/mlx_server/schemas/anthropic.py"
      provides: "Anthropic Messages API request/response schemas"
      exports: ["AnthropicMessagesRequest", "AnthropicMessagesResponse", "MessageParam", "ContentBlock"]
    - path: "backend/tests/mlx_server/schemas/test_anthropic.py"
      provides: "Schema validation tests"
      min_lines: 50
  key_links:
    - from: "schemas/anthropic.py"
      to: "pydantic BaseModel"
      via: "inheritance"
      pattern: "class.*BaseModel"
---

<objective>
Create Anthropic Messages API Pydantic schemas for request validation and response formatting.

Purpose: Enable type-safe handling of Anthropic-format requests before protocol translation.
Output: Complete Anthropic schemas with request, response, and streaming event types.
</objective>

<execution_context>
@.claude/get-shit-done/workflows/execute-plan.md
@.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-dual-protocol-cloud-fallback/10-RESEARCH.md
@backend/mlx_manager/mlx_server/schemas/openai.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Anthropic Messages API schemas</name>
  <files>backend/mlx_manager/mlx_server/schemas/anthropic.py</files>
  <action>
Create Pydantic v2 schemas for Anthropic Messages API based on research document patterns:

1. Content block types:
   - TextBlockParam: type="text", text: str
   - ImageBlockParam: type="image", source: ImageSource (with type, media_type, data)
   - ContentBlock union type

2. MessageParam:
   - role: Literal["user", "assistant"] (NOT system - that's separate)
   - content: str | list[ContentBlock]

3. AnthropicMessagesRequest:
   - model: str (required)
   - max_tokens: int = Field(ge=1) - REQUIRED field (unlike OpenAI)
   - messages: list[MessageParam]
   - system: str | list[TextBlockParam] | None = None (separate from messages)
   - temperature: float = Field(default=1.0, ge=0.0, le=1.0)
   - top_p: float | None = None
   - top_k: int | None = None
   - stop_sequences: list[str] | None = None
   - stream: bool = False
   - metadata: dict | None = None

4. Response schemas:
   - TextBlock: type="text", text: str
   - Usage: input_tokens: int, output_tokens: int
   - AnthropicMessagesResponse:
     - id: str
     - type: Literal["message"] = "message"
     - role: Literal["assistant"] = "assistant"
     - model: str
     - content: list[TextBlock]
     - stop_reason: Literal["end_turn", "max_tokens", "stop_sequence", "tool_use"] | None
     - stop_sequence: str | None = None
     - usage: Usage

5. Streaming event schemas (for SSE):
   - MessageStartEvent
   - ContentBlockStartEvent
   - ContentBlockDeltaEvent (with TextDelta)
   - ContentBlockStopEvent
   - MessageDeltaEvent
   - MessageStopEvent

Add helper function `extract_anthropic_content(content)` to normalize content to string.
  </action>
  <verify>
cd /Users/atomasini/Development/mlx-manager/backend && python -c "
from mlx_manager.mlx_server.schemas.anthropic import (
    AnthropicMessagesRequest,
    AnthropicMessagesResponse,
    MessageParam,
    TextBlockParam,
)
# Test required max_tokens
try:
    AnthropicMessagesRequest(model='test', messages=[])
    print('FAIL: max_tokens should be required')
except Exception:
    print('OK: max_tokens is required')
# Test valid request
req = AnthropicMessagesRequest(
    model='claude-3',
    max_tokens=1000,
    messages=[MessageParam(role='user', content='Hello')],
    system='You are helpful'
)
print(f'OK: Request created with system: {req.system}')
"
  </verify>
  <done>Anthropic schemas importable and validate max_tokens as required</done>
</task>

<task type="auto">
  <name>Task 2: Add schema unit tests</name>
  <files>backend/tests/mlx_server/schemas/test_anthropic.py</files>
  <action>
Create comprehensive tests for Anthropic schemas:

1. Test request validation:
   - max_tokens is required (raises without it)
   - Valid request with string content
   - Valid request with content blocks (text + image)
   - System message handling (string and list of TextBlockParam)
   - Temperature bounds validation (0.0 to 1.0)

2. Test response validation:
   - Valid response with text content
   - Stop reason enum values
   - Usage token counts

3. Test content extraction helper:
   - String content returns string
   - List of TextBlockParam returns concatenated text
   - Mixed content extracts text portions

4. Test streaming event schemas:
   - MessageStartEvent structure
   - ContentBlockDeltaEvent with TextDelta
  </action>
  <verify>cd /Users/atomasini/Development/mlx-manager/backend && python -m pytest tests/mlx_server/schemas/test_anthropic.py -v</verify>
  <done>All Anthropic schema tests passing</done>
</task>

</tasks>

<verification>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
# Run schema tests
python -m pytest tests/mlx_server/schemas/test_anthropic.py -v

# Verify imports work
python -c "from mlx_manager.mlx_server.schemas.anthropic import *; print('OK')"

# Type checking
mypy mlx_manager/mlx_server/schemas/anthropic.py
```
</verification>

<success_criteria>
- AnthropicMessagesRequest validates max_tokens as required
- System message stored separately from messages array
- Content blocks support both string and list[ContentBlock]
- All streaming event schemas defined
- Tests pass with > 90% coverage of schema code
</success_criteria>

<output>
After completion, create `.planning/phases/10-dual-protocol-cloud-fallback/10-01-SUMMARY.md`
</output>
