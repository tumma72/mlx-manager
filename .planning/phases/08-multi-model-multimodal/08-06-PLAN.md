---
phase: 08-multi-model-multimodal
plan: 06
type: execute
wave: 3
depends_on: ["08-01", "08-03"]
files_modified:
  - backend/mlx_manager/mlx_server/api/v1/admin.py
  - backend/mlx_manager/mlx_server/main.py
  - backend/tests/mlx_server/test_admin.py
autonomous: true

must_haves:
  truths:
    - "POST /admin/models/load/{model_id} preloads model protected from eviction"
    - "POST /admin/models/unload/{model_id} unloads model from pool"
    - "GET /admin/models/status returns loaded models with metadata"
    - "Pool status includes memory usage and per-model details"
  artifacts:
    - path: "backend/mlx_manager/mlx_server/api/v1/admin.py"
      provides: "Admin endpoints for model management"
      exports: ["router"]
  key_links:
    - from: "admin.py"
      to: "pool.py"
      via: "import get_model_pool, preload_model, unload_model"
      pattern: "from.*pool import.*get_model_pool"
    - from: "main.py"
      to: "admin.py"
      via: "include_router"
      pattern: "include_router.*admin"
---

<objective>
Implement admin endpoints for model preload/unload and pool status

Purpose: Enable administrators to explicitly preload models (protected from eviction), unload models to free memory, and monitor pool status including loaded models and memory usage.

Output: Admin API router with model management endpoints
</objective>

<execution_context>
@.claude/get-shit-done/workflows/execute-plan.md
@.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-multi-model-multimodal/08-RESEARCH.md
@backend/mlx_manager/mlx_server/models/pool.py
@backend/mlx_manager/mlx_server/main.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create admin API router with model management endpoints</name>
  <files>backend/mlx_manager/mlx_server/api/v1/admin.py</files>
  <action>
Create admin.py with endpoints for model management:

```python
"""Admin API endpoints for model pool management.

These endpoints allow administrators to:
- Preload models (protected from LRU eviction)
- Unload models to free memory
- Monitor pool status and memory usage
"""

import logging
from typing import Any

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

from mlx_manager.mlx_server.models.pool import get_model_pool
from mlx_manager.mlx_server.utils.memory import get_memory_usage

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/admin", tags=["admin"])


# --- Response Models ---


class ModelStatus(BaseModel):
    """Status of a loaded model."""

    model_id: str
    model_type: str
    size_gb: float
    preloaded: bool
    last_used: float
    loaded_at: float


class PoolStatusResponse(BaseModel):
    """Model pool status response."""

    loaded_models: list[ModelStatus]
    total_models: int
    memory: dict[str, Any]
    max_memory_gb: float
    max_models: int


class ModelLoadResponse(BaseModel):
    """Response for model load operation."""

    status: str
    model_id: str
    model_type: str
    size_gb: float
    preloaded: bool


class ModelUnloadResponse(BaseModel):
    """Response for model unload operation."""

    status: str
    model_id: str


# --- Endpoints ---


@router.get("/models/status", response_model=PoolStatusResponse)
async def pool_status() -> PoolStatusResponse:
    """Get current model pool status.

    Returns list of loaded models with their metadata, memory usage,
    and pool configuration.
    """
    pool = get_model_pool()
    memory = get_memory_usage()

    models = [
        ModelStatus(
            model_id=model_id,
            model_type=m.model_type,
            size_gb=m.size_gb,
            preloaded=m.preloaded,
            last_used=m.last_used,
            loaded_at=m.loaded_at,
        )
        for model_id, m in pool._models.items()
    ]

    return PoolStatusResponse(
        loaded_models=models,
        total_models=len(models),
        memory=memory,
        max_memory_gb=pool.max_memory_gb,
        max_models=pool.max_models,
    )


@router.post("/models/load/{model_id:path}", response_model=ModelLoadResponse)
async def preload_model(model_id: str) -> ModelLoadResponse:
    """Preload a model into the pool.

    Preloaded models are protected from LRU eviction. Use this to ensure
    a model stays loaded even under memory pressure.

    Args:
        model_id: HuggingFace model ID (e.g., mlx-community/Llama-3.2-3B-4bit)
    """
    pool = get_model_pool()

    logger.info(f"Admin: Preloading model {model_id}")

    try:
        loaded = await pool.preload_model(model_id)

        return ModelLoadResponse(
            status="loaded",
            model_id=model_id,
            model_type=loaded.model_type,
            size_gb=loaded.size_gb,
            preloaded=True,
        )

    except Exception as e:
        logger.error(f"Admin: Failed to preload {model_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e)) from e


@router.post("/models/unload/{model_id:path}", response_model=ModelUnloadResponse)
async def unload_model(model_id: str) -> ModelUnloadResponse:
    """Unload a model from the pool.

    Frees memory by removing the model from the pool. This works for both
    preloaded and on-demand loaded models.

    Args:
        model_id: HuggingFace model ID to unload
    """
    pool = get_model_pool()

    logger.info(f"Admin: Unloading model {model_id}")

    success = await pool.unload_model(model_id)

    if not success:
        raise HTTPException(
            status_code=404,
            detail=f"Model not loaded: {model_id}",
        )

    return ModelUnloadResponse(
        status="unloaded",
        model_id=model_id,
    )


@router.get("/health")
async def admin_health() -> dict[str, str]:
    """Admin health check endpoint."""
    return {"status": "healthy"}
```
  </action>
  <verify>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
python -c "
from mlx_manager.mlx_server.api.v1.admin import router
print('Admin router prefix:', router.prefix)
print('Admin routes:', [r.path for r in router.routes])
"
```
Should show prefix /admin and routes for status, load, unload, health
  </verify>
  <done>
- GET /admin/models/status endpoint created
- POST /admin/models/load/{model_id} endpoint created
- POST /admin/models/unload/{model_id} endpoint created
- Response models defined
  </done>
</task>

<task type="auto">
  <name>Task 2: Register admin router in main.py</name>
  <files>backend/mlx_manager/mlx_server/main.py</files>
  <action>
Update main.py to include the admin router:

1. **Add import near the top** (with other router imports):
```python
from mlx_manager.mlx_server.api.v1.admin import router as admin_router
```

2. **Add router registration** (after existing router registrations):
```python
app.include_router(admin_router)
```

Find where other routers are registered (chat_router, completions_router, models_router, embeddings_router) and add the admin router in the same section.
  </action>
  <verify>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
python -c "
from mlx_manager.mlx_server.main import app

# Check that admin routes are registered
routes = [r.path for r in app.routes if hasattr(r, 'path')]
assert '/admin/models/status' in routes, f'Admin status route not found. Routes: {routes}'
assert '/admin/health' in routes, f'Admin health route not found. Routes: {routes}'
print('Admin routes registered correctly')
"
```
  </verify>
  <done>Admin router registered in FastAPI app</done>
</task>

<task type="auto">
  <name>Task 3: Add unit tests for admin endpoints</name>
  <files>backend/tests/mlx_server/test_admin.py</files>
  <action>
Create test_admin.py:

```python
"""Tests for admin API endpoints."""

import pytest
from unittest.mock import AsyncMock, MagicMock, patch

from mlx_manager.mlx_server.api.v1.admin import (
    pool_status,
    preload_model,
    unload_model,
    PoolStatusResponse,
    ModelLoadResponse,
    ModelUnloadResponse,
)


class TestPoolStatus:
    """Tests for /admin/models/status endpoint."""

    @pytest.mark.asyncio
    @patch("mlx_manager.mlx_server.api.v1.admin.get_model_pool")
    @patch("mlx_manager.mlx_server.api.v1.admin.get_memory_usage")
    async def test_pool_status_empty(self, mock_memory, mock_get_pool):
        """Test pool status with no models loaded."""
        mock_pool = MagicMock()
        mock_pool._models = {}
        mock_pool.max_memory_gb = 48.0
        mock_pool.max_models = 4
        mock_get_pool.return_value = mock_pool

        mock_memory.return_value = {"active_gb": 0.0, "cache_gb": 0.0}

        response = await pool_status()

        assert isinstance(response, PoolStatusResponse)
        assert response.total_models == 0
        assert len(response.loaded_models) == 0
        assert response.max_memory_gb == 48.0

    @pytest.mark.asyncio
    @patch("mlx_manager.mlx_server.api.v1.admin.get_model_pool")
    @patch("mlx_manager.mlx_server.api.v1.admin.get_memory_usage")
    async def test_pool_status_with_models(self, mock_memory, mock_get_pool):
        """Test pool status with loaded models."""
        # Create mock loaded model
        mock_loaded = MagicMock()
        mock_loaded.model_type = "text-gen"
        mock_loaded.size_gb = 4.5
        mock_loaded.preloaded = True
        mock_loaded.last_used = 1234567890.0
        mock_loaded.loaded_at = 1234567800.0

        mock_pool = MagicMock()
        mock_pool._models = {"test-model": mock_loaded}
        mock_pool.max_memory_gb = 48.0
        mock_pool.max_models = 4
        mock_get_pool.return_value = mock_pool

        mock_memory.return_value = {"active_gb": 4.5, "cache_gb": 0.5}

        response = await pool_status()

        assert response.total_models == 1
        assert len(response.loaded_models) == 1
        assert response.loaded_models[0].model_id == "test-model"
        assert response.loaded_models[0].model_type == "text-gen"
        assert response.loaded_models[0].preloaded is True


class TestPreloadModel:
    """Tests for /admin/models/load endpoint."""

    @pytest.mark.asyncio
    @patch("mlx_manager.mlx_server.api.v1.admin.get_model_pool")
    async def test_preload_model_success(self, mock_get_pool):
        """Test successful model preload."""
        mock_loaded = MagicMock()
        mock_loaded.model_type = "text-gen"
        mock_loaded.size_gb = 4.0
        mock_loaded.preloaded = True

        mock_pool = MagicMock()
        mock_pool.preload_model = AsyncMock(return_value=mock_loaded)
        mock_get_pool.return_value = mock_pool

        response = await preload_model("mlx-community/test-model")

        assert isinstance(response, ModelLoadResponse)
        assert response.status == "loaded"
        assert response.model_id == "mlx-community/test-model"
        assert response.preloaded is True
        mock_pool.preload_model.assert_called_once_with("mlx-community/test-model")

    @pytest.mark.asyncio
    @patch("mlx_manager.mlx_server.api.v1.admin.get_model_pool")
    async def test_preload_model_failure(self, mock_get_pool):
        """Test preload failure returns 500."""
        from fastapi import HTTPException

        mock_pool = MagicMock()
        mock_pool.preload_model = AsyncMock(side_effect=RuntimeError("Load failed"))
        mock_get_pool.return_value = mock_pool

        with pytest.raises(HTTPException) as exc_info:
            await preload_model("bad-model")

        assert exc_info.value.status_code == 500
        assert "Load failed" in exc_info.value.detail


class TestUnloadModel:
    """Tests for /admin/models/unload endpoint."""

    @pytest.mark.asyncio
    @patch("mlx_manager.mlx_server.api.v1.admin.get_model_pool")
    async def test_unload_model_success(self, mock_get_pool):
        """Test successful model unload."""
        mock_pool = MagicMock()
        mock_pool.unload_model = AsyncMock(return_value=True)
        mock_get_pool.return_value = mock_pool

        response = await unload_model("test-model")

        assert isinstance(response, ModelUnloadResponse)
        assert response.status == "unloaded"
        assert response.model_id == "test-model"
        mock_pool.unload_model.assert_called_once_with("test-model")

    @pytest.mark.asyncio
    @patch("mlx_manager.mlx_server.api.v1.admin.get_model_pool")
    async def test_unload_model_not_found(self, mock_get_pool):
        """Test unload of non-existent model returns 404."""
        from fastapi import HTTPException

        mock_pool = MagicMock()
        mock_pool.unload_model = AsyncMock(return_value=False)
        mock_get_pool.return_value = mock_pool

        with pytest.raises(HTTPException) as exc_info:
            await unload_model("not-loaded-model")

        assert exc_info.value.status_code == 404
        assert "not loaded" in exc_info.value.detail.lower()


class TestAdminHealth:
    """Tests for /admin/health endpoint."""

    @pytest.mark.asyncio
    async def test_admin_health(self):
        """Test admin health endpoint returns healthy."""
        from mlx_manager.mlx_server.api.v1.admin import admin_health

        response = await admin_health()
        assert response["status"] == "healthy"
```
  </action>
  <verify>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
pytest tests/mlx_server/test_admin.py -v
```
All tests should pass
  </verify>
  <done>
- Tests cover pool status endpoint (empty and with models)
- Tests cover preload success and failure
- Tests cover unload success and not found
- Tests cover health endpoint
  </done>
</task>

</tasks>

<verification>
After all tasks:
```bash
cd /Users/atomasini/Development/mlx-manager/backend
# Type check
mypy mlx_manager/mlx_server/api/v1/admin.py
# Lint
ruff check mlx_manager/mlx_server/api/v1/admin.py
# Tests
pytest tests/mlx_server/test_admin.py -v
```
All checks should pass.
</verification>

<success_criteria>
- GET /admin/models/status returns loaded models with metadata
- POST /admin/models/load/{model_id} preloads model with eviction protection
- POST /admin/models/unload/{model_id} unloads model and frees memory
- 404 returned when unloading non-existent model
- 500 returned when preload fails
- Admin router registered in main.py
- Unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/08-multi-model-multimodal/08-06-SUMMARY.md`
</output>
