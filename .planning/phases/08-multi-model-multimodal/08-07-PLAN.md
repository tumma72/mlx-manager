---
phase: 08-multi-model-multimodal
plan: 07
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/mlx_manager/mlx_server/models/adapters/gemma.py
  - backend/mlx_manager/mlx_server/models/adapters/qwen.py
  - backend/mlx_manager/mlx_server/models/adapters/llama.py
  - backend/mlx_manager/mlx_server/models/adapters/mistral.py
  - backend/mlx_manager/mlx_server/services/image_processor.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Vision models work with all adapters (Gemma, Qwen, Llama, Mistral)"
    - "Image URLs can be fetched from Wikipedia and other User-Agent-requiring sites"
  artifacts:
    - path: "backend/mlx_manager/mlx_server/models/adapters/gemma.py"
      provides: "Processor-aware get_stop_tokens()"
      contains: "getattr.*tokenizer"
    - path: "backend/mlx_manager/mlx_server/models/adapters/qwen.py"
      provides: "Processor-aware get_stop_tokens()"
      contains: "getattr.*tokenizer"
    - path: "backend/mlx_manager/mlx_server/models/adapters/llama.py"
      provides: "Processor-aware get_stop_tokens()"
      contains: "getattr.*tokenizer"
    - path: "backend/mlx_manager/mlx_server/models/adapters/mistral.py"
      provides: "Processor-aware get_stop_tokens()"
      contains: "getattr.*tokenizer"
    - path: "backend/mlx_manager/mlx_server/services/image_processor.py"
      provides: "User-Agent header in httpx client"
      contains: "User-Agent"
  key_links:
    - from: "adapters/*.py get_stop_tokens()"
      to: "Processor.tokenizer.eos_token_id"
      via: "getattr fallback"
      pattern: "getattr\\(tokenizer.*tokenizer.*tokenizer\\)"
---

<objective>
Fix vision model compatibility with all adapters and image URL fetching.

Purpose: Close UAT gaps from Phase 8 testing where vision models fail due to Processor vs Tokenizer mismatch and Wikipedia URLs return 403.
Output: All adapters handle Processor objects; image fetching works with User-Agent-requiring sites.
</objective>

<execution_context>
@.claude/get-shit-done/workflows/execute-plan.md
@.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-multi-model-multimodal/08-UAT.md

# Existing adapter implementations
@backend/mlx_manager/mlx_server/models/adapters/gemma.py
@backend/mlx_manager/mlx_server/models/adapters/qwen.py
@backend/mlx_manager/mlx_server/models/adapters/llama.py
@backend/mlx_manager/mlx_server/models/adapters/mistral.py
@backend/mlx_manager/mlx_server/services/image_processor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix Processor compatibility in all adapters</name>
  <files>
    backend/mlx_manager/mlx_server/models/adapters/gemma.py
    backend/mlx_manager/mlx_server/models/adapters/qwen.py
    backend/mlx_manager/mlx_server/models/adapters/llama.py
    backend/mlx_manager/mlx_server/models/adapters/mistral.py
  </files>
  <action>
    Update get_stop_tokens() in ALL four adapters to handle both Tokenizer and Processor objects.

    **Root cause:** Vision models (Gemma3, Qwen-VL, LLaVA) use Processor objects that wrap a tokenizer. Direct access to tokenizer.eos_token_id fails because Processor doesn't expose this attribute directly.

    **Fix pattern:** Extract the actual tokenizer using getattr fallback:
    ```python
    # Get actual tokenizer (Processor wraps tokenizer, regular tokenizer is itself)
    actual_tokenizer = getattr(tokenizer, "tokenizer", tokenizer)
    ```

    Then use actual_tokenizer.eos_token_id and actual_tokenizer.convert_tokens_to_ids().

    **Update each adapter's get_stop_tokens():**

    1. gemma.py (line 40): Change `tokenizer.eos_token_id` to use extracted actual_tokenizer
    2. qwen.py (line 41): Same fix
    3. llama.py (line 62): Same fix
    4. mistral.py (line 63): Same fix

    Also update any convert_tokens_to_ids() calls to use actual_tokenizer.

    **Example for gemma.py:**
    ```python
    def get_stop_tokens(self, tokenizer: Any) -> list[int]:
        """Get Gemma stop tokens.

        Gemma uses <end_of_turn> as the end-of-turn marker.
        Must include both eos_token_id and <end_of_turn> to prevent runaway generation.

        Handles both Tokenizer and Processor objects (vision models use Processor).
        """
        # Get actual tokenizer (Processor wraps tokenizer, regular tokenizer is itself)
        actual_tokenizer = getattr(tokenizer, "tokenizer", tokenizer)
        stop_tokens = [actual_tokenizer.eos_token_id]

        # Add <end_of_turn> token
        try:
            end_turn_id = actual_tokenizer.convert_tokens_to_ids("<end_of_turn>")
            if end_turn_id is not None and end_turn_id != actual_tokenizer.unk_token_id:
                stop_tokens.append(end_turn_id)
        except Exception:
            pass

        return stop_tokens
    ```

    Apply the same pattern to qwen.py, llama.py, and mistral.py, preserving their specific stop token logic.
  </action>
  <verify>
    Run adapter tests: `cd backend && pytest tests/mlx_server/models/adapters/ -v`
    Run type checking: `cd backend && mypy mlx_manager/mlx_server/models/adapters/`
  </verify>
  <done>
    All four adapters handle Processor objects without AttributeError.
    Tests pass and type checking clean.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add User-Agent header to image fetching</name>
  <files>backend/mlx_manager/mlx_server/services/image_processor.py</files>
  <action>
    Update the httpx client creation in image_processor.py to include a User-Agent header.

    **Root cause:** Wikipedia and other sites return 403 Forbidden when requests lack a User-Agent header.

    **Fix:** Add headers parameter when creating AsyncClient instances.

    1. Add a module-level constant for default headers:
    ```python
    DEFAULT_HEADERS = {
        "User-Agent": "MLX-Manager/1.0 (https://github.com/user/mlx-manager; image-fetch)"
    }
    ```

    2. Update _fetch_image_from_url() (line 108):
    ```python
    if client is None:
        client = httpx.AsyncClient(headers=DEFAULT_HEADERS)
        should_close = True
    ```

    3. Update preprocess_images() (line 153):
    ```python
    if client is None:
        client = httpx.AsyncClient(headers=DEFAULT_HEADERS)
        should_close = True
    ```

    This ensures all internal httpx clients include User-Agent by default while allowing callers to pass their own configured client.
  </action>
  <verify>
    Run image processor tests: `cd backend && pytest tests/mlx_server/services/test_image_processor.py -v`
    Run type checking: `cd backend && mypy mlx_manager/mlx_server/services/image_processor.py`
  </verify>
  <done>
    Image processor creates httpx clients with User-Agent header.
    Tests pass and type checking clean.
  </done>
</task>

</tasks>

<verification>
1. All adapter tests pass: `cd backend && pytest tests/mlx_server/models/adapters/ -v`
2. Image processor tests pass: `cd backend && pytest tests/mlx_server/services/test_image_processor.py -v`
3. Full test suite passes: `cd backend && pytest -v`
4. Type checking passes: `cd backend && mypy mlx_manager`
5. Linting passes: `cd backend && ruff check mlx_manager`
</verification>

<success_criteria>
- Vision models (Gemma3, Qwen-VL) can load and generate without AttributeError on eos_token_id
- Image URLs from User-Agent-requiring sites (Wikipedia) fetch successfully
- All existing tests continue to pass
- No new type errors or lint warnings
</success_criteria>

<output>
After completion, create `.planning/phases/08-multi-model-multimodal/08-07-SUMMARY.md`
</output>
