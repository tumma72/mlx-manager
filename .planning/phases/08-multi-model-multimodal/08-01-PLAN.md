---
phase: 08-multi-model-multimodal
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/mlx_manager/mlx_server/models/types.py
  - backend/mlx_manager/mlx_server/models/pool.py
  - backend/tests/mlx_server/test_pool.py
autonomous: true

must_haves:
  truths:
    - "Pool supports multiple hot models simultaneously"
    - "LRU eviction removes least-recently-used models when memory pressure detected"
    - "Preloaded models are protected from eviction"
    - "Memory limit configurable as percentage OR absolute GB"
    - "503 error returned when insufficient memory after eviction"
  artifacts:
    - path: "backend/mlx_manager/mlx_server/models/types.py"
      provides: "ModelType enum (TEXT_GEN, VISION, EMBEDDINGS)"
      exports: ["ModelType"]
    - path: "backend/mlx_manager/mlx_server/models/pool.py"
      provides: "Enhanced ModelPoolManager with LRU eviction"
      contains: ["_evict_lru", "preload_model", "_ensure_memory_for_load"]
  key_links:
    - from: "pool.py"
      to: "types.py"
      via: "import ModelType"
      pattern: "from.*types import.*ModelType"
---

<objective>
Enhance ModelPoolManager with multi-model LRU eviction and model type tracking

Purpose: Enable the server to hot-swap multiple models with automatic memory management, protecting preloaded models from eviction while freeing memory for new model requests.

Output: Extended pool.py with LRU eviction, preload protection, and configurable memory limits
</objective>

<execution_context>
@.claude/get-shit-done/workflows/execute-plan.md
@.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-multi-model-multimodal/08-RESEARCH.md
@.planning/phases/08-multi-model-multimodal/08-CONTEXT.md
@backend/mlx_manager/mlx_server/models/pool.py
@backend/mlx_manager/mlx_server/utils/memory.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ModelType enum and extend LoadedModel</name>
  <files>backend/mlx_manager/mlx_server/models/types.py</files>
  <action>
Create new types.py file with:

1. **ModelType enum** with values: TEXT_GEN = "text-gen", VISION = "vision", EMBEDDINGS = "embeddings"

2. Do NOT define LoadedModel here - it will be extended in pool.py directly to avoid circular imports

This is a minimal types file that can be imported by pool.py, inference.py, and future vision/embeddings services.
  </action>
  <verify>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
python -c "from mlx_manager.mlx_server.models.types import ModelType; print(ModelType.TEXT_GEN.value)"
```
Should output: text-gen
  </verify>
  <done>ModelType enum exists with TEXT_GEN, VISION, EMBEDDINGS values</done>
</task>

<task type="auto">
  <name>Task 2: Enhance ModelPoolManager with LRU eviction and multi-model support</name>
  <files>backend/mlx_manager/mlx_server/models/pool.py</files>
  <action>
Extend the existing ModelPoolManager in pool.py:

1. **Extend LoadedModel dataclass** (add new fields, keep existing ones):
   - `model_type: str = "text-gen"` - Type of model (from ModelType enum values)
   - `preloaded: bool = False` - Whether protected from eviction
   - Keep existing: model_id, model, tokenizer, loaded_at, last_used, size_gb

2. **Add constructor parameters** to ModelPoolManager.__init__:
   - `memory_limit_pct: float | None = None` - Alternative to max_memory_gb (e.g., 0.75 = 75%)
   - Change `max_models: int = 1` to `max_models: int = 4` (default to 4 hot models)

3. **Add _get_effective_memory_limit() method**:
   - If memory_limit_pct is set, calculate from total system memory using psutil
   - Otherwise return max_memory_gb
   - Import psutil at top of file

4. **Add _current_memory_gb() method**:
   - Sum of all loaded model sizes: `sum(m.size_gb for m in self._models.values())`

5. **Add _evictable_models() method**:
   - Return list of models where `preloaded == False`

6. **Add async _evict_lru() method**:
   - Find LRU model among evictable models: `min(evictable, key=lambda m: m.last_used)`
   - Delete from _models dict
   - Call clear_cache()
   - Log which model was evicted

7. **Add async _ensure_memory_for_load(model_id) method**:
   - Calculate estimated size using _estimate_model_size()
   - Loop: while (current + estimated > limit) and evictable models exist, call _evict_lru()
   - After loop, if still over limit, raise HTTPException(503) with message:
     "Insufficient memory: need {X:.1f}GB, only {Y:.1f}GB available after eviction"
   - Import HTTPException from fastapi

8. **Add _estimate_model_size(model_id) method**:
   - Heuristic based on model name patterns:
     - "3b" or "3B" -> 2.0 GB
     - "7b" or "7B" -> 4.0 GB
     - "8b" or "8B" -> 5.0 GB
     - "13b" or "13B" -> 8.0 GB
     - "70b" or "70B" -> 40.0 GB
     - Default: 4.0 GB
   - Use regex to find pattern like r"(\d+)[bB]" in model_id

9. **Modify get_model()** to call _ensure_memory_for_load() before loading

10. **Add async preload_model(model_id) method**:
    - Call get_model() to load
    - Set loaded.preloaded = True
    - Return loaded model

IMPORTANT: Keep all existing functionality working (get_model, unload_model, cleanup, etc.)
  </action>
  <verify>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
python -c "
from mlx_manager.mlx_server.models.pool import ModelPoolManager, LoadedModel
pool = ModelPoolManager(max_memory_gb=16.0, max_models=4)
print('max_memory_gb:', pool.max_memory_gb)
print('max_models:', pool.max_models)
lm = LoadedModel(model_id='test', model=None, tokenizer=None, model_type='text-gen', preloaded=False)
print('model_type:', lm.model_type)
print('preloaded:', lm.preloaded)
"
```
Should show max_memory_gb: 16.0, max_models: 4, model_type: text-gen, preloaded: False
  </verify>
  <done>
- LoadedModel has model_type and preloaded fields
- ModelPoolManager has memory_limit_pct parameter
- _evict_lru() method exists
- _ensure_memory_for_load() method exists
- preload_model() method exists
  </done>
</task>

<task type="auto">
  <name>Task 3: Add unit tests for LRU eviction and multi-model pool</name>
  <files>backend/tests/mlx_server/test_pool.py</files>
  <action>
Create or extend test_pool.py with tests for the new pool functionality:

1. **test_loaded_model_fields**: Verify LoadedModel has model_type and preloaded fields with defaults

2. **test_pool_memory_limit_absolute**: Create pool with max_memory_gb, verify _get_effective_memory_limit() returns it

3. **test_pool_memory_limit_percentage**: Create pool with memory_limit_pct=0.5, verify calculation uses psutil (mock psutil.virtual_memory to return fixed value)

4. **test_estimate_model_size**: Test _estimate_model_size() returns correct values for "3B", "7B", "13B" patterns

5. **test_evictable_models**: Add models with preloaded=True and False, verify _evictable_models() only returns non-preloaded

6. **test_evict_lru**: Add multiple models with different last_used times, verify _evict_lru() removes the oldest non-preloaded one

7. **test_preload_protection**: Preload a model, verify it survives eviction when other models are evictable

8. **test_insufficient_memory_error**: Set up pool with very small limit, mock model load to require more memory, verify 503 HTTPException raised

Use pytest fixtures and unittest.mock for mocking mlx_lm.load and memory functions. These tests should NOT actually load real MLX models - mock everything.
  </action>
  <verify>
```bash
cd /Users/atomasini/Development/mlx-manager/backend
pytest tests/mlx_server/test_pool.py -v
```
All tests should pass
  </verify>
  <done>
- Tests cover LoadedModel new fields
- Tests cover memory limit calculation (absolute and percentage)
- Tests cover model size estimation
- Tests cover LRU eviction logic
- Tests cover preload protection
- Tests cover 503 error on insufficient memory
  </done>
</task>

</tasks>

<verification>
After all tasks:
```bash
cd /Users/atomasini/Development/mlx-manager/backend
# Type check
mypy mlx_manager/mlx_server/models/pool.py mlx_manager/mlx_server/models/types.py
# Lint
ruff check mlx_manager/mlx_server/models/
# Tests
pytest tests/mlx_server/test_pool.py -v
```
All checks should pass.
</verification>

<success_criteria>
- ModelType enum defined with TEXT_GEN, VISION, EMBEDDINGS
- LoadedModel extended with model_type and preloaded fields
- ModelPoolManager supports configurable memory limit (GB or percentage)
- LRU eviction removes least-recently-used non-preloaded models
- Preloaded models are never evicted
- 503 error raised when memory insufficient even after eviction
- Unit tests pass for all new functionality
</success_criteria>

<output>
After completion, create `.planning/phases/08-multi-model-multimodal/08-01-SUMMARY.md`
</output>
