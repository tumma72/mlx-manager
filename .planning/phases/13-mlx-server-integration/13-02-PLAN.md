---
phase: 13-mlx-server-integration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/mlx_manager/services/server_manager.py
  - backend/mlx_manager/utils/command_builder.py
  - backend/mlx_manager/services/parser_options.py
  - backend/mlx_manager/routers/servers.py
  - backend/mlx_manager/main.py
autonomous: true

must_haves:
  truths:
    - "No mlx-openai-server subprocess management code exists"
    - "Servers router returns simplified status (embedded server always running)"
    - "No references to command_builder or parser_options"
  artifacts:
    - path: "backend/mlx_manager/services/server_manager.py"
      provides: "DELETED"
    - path: "backend/mlx_manager/utils/command_builder.py"
      provides: "DELETED"
    - path: "backend/mlx_manager/services/parser_options.py"
      provides: "DELETED"
    - path: "backend/mlx_manager/routers/servers.py"
      provides: "Simplified server status API"
  key_links: []
---

<objective>
Remove legacy mlx-openai-server subprocess management code

Purpose: Delete all code related to managing external mlx-openai-server processes since the embedded MLX Server handles inference directly. This removes deprecated dependencies and simplifies the codebase.

Output: Codebase with no references to mlx-openai-server, server_manager subprocess handling, or related utilities.
</objective>

<execution_context>
@.claude/get-shit-done/workflows/execute-plan.md
@.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@backend/mlx_manager/services/server_manager.py
@backend/mlx_manager/utils/command_builder.py
@backend/mlx_manager/services/parser_options.py
@backend/mlx_manager/routers/servers.py
@backend/mlx_manager/main.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Delete legacy subprocess management files</name>
  <files>
    backend/mlx_manager/services/server_manager.py
    backend/mlx_manager/utils/command_builder.py
    backend/mlx_manager/services/parser_options.py
  </files>
  <action>
Delete the following files completely:

1. `backend/mlx_manager/services/server_manager.py` - Subprocess management for mlx-openai-server
2. `backend/mlx_manager/utils/command_builder.py` - CLI command building for mlx-openai-server
3. `backend/mlx_manager/services/parser_options.py` - Parser options discovery from mlx-openai-server

Use `git rm` to properly stage deletions:
```bash
git rm backend/mlx_manager/services/server_manager.py
git rm backend/mlx_manager/utils/command_builder.py
git rm backend/mlx_manager/services/parser_options.py
```

Also check and remove any imports of these modules in `__init__.py` files:
- `backend/mlx_manager/services/__init__.py` - Remove server_manager import if present
- `backend/mlx_manager/utils/__init__.py` - Remove command_builder import if present
  </action>
  <verify>
- Files no longer exist on filesystem
- `git status` shows files staged for deletion
- No broken imports when running `python -c "import mlx_manager"`
  </verify>
  <done>Legacy subprocess management files deleted from codebase</done>
</task>

<task type="auto">
  <name>Task 2: Simplify servers router for embedded server</name>
  <files>backend/mlx_manager/routers/servers.py</files>
  <action>
Rewrite servers.py to work with embedded MLX Server instead of subprocess management:

1. Remove all imports of server_manager:
   ```python
   # DELETE: from mlx_manager.services.server_manager import server_manager
   ```

2. Modify `list_running_servers()`:
   - Since MLX Server is always embedded and running, return status based on model pool
   - Import model pool: `from mlx_manager.mlx_server.models.pool import get_model_pool`
   - Return list of loaded models as "running servers"

3. Remove/modify subprocess endpoints:
   - `POST /{profile_id}/start` - REMOVE (server is always running)
   - `POST /{profile_id}/stop` - REMOVE (server is always running)
   - `POST /{profile_id}/restart` - REMOVE (server is always running)

4. Update `GET /{profile_id}/health`:
   - Check if requested model is loaded in the pool
   - Return healthy if model available, loading if being loaded

5. Update `GET /{profile_id}/status`:
   - Return embedded server status
   - Include model pool info (loaded models, memory usage)

6. Remove `GET /{profile_id}/logs`:
   - No subprocess logs to stream
   - Or redirect to LogFire/audit logs

New simplified router structure:
```python
@router.get("", response_model=list[EmbeddedServerStatus])
async def list_servers():
    """Return embedded MLX Server status with loaded models."""
    try:
        pool = get_model_pool()
        loaded_models = pool.get_loaded_models()
        return [{
            "status": "running",
            "type": "embedded",
            "loaded_models": loaded_models,
        }]
    except RuntimeError:
        return [{"status": "not_initialized", "type": "embedded"}]

@router.get("/models")
async def list_loaded_models():
    """List models currently loaded in the embedded server."""
    pool = get_model_pool()
    return pool.get_loaded_models()
```

Note: Keep API compatibility where possible, but remove endpoints that no longer make sense.
  </action>
  <verify>
- `cd backend && python -c "from mlx_manager.routers.servers import router"` imports without error
- No references to server_manager in the file
- `grep -r "server_manager" backend/mlx_manager/routers/` returns nothing
  </verify>
  <done>Servers router simplified for embedded server model</done>
</task>

<task type="auto">
  <name>Task 3: Remove server_manager from main.py</name>
  <files>backend/mlx_manager/main.py</files>
  <action>
Remove all references to server_manager from main.py:

1. Remove import:
   ```python
   # DELETE: from mlx_manager.services.server_manager import server_manager
   ```

2. Remove `cleanup_stale_instances()` function - no longer needed without subprocess tracking

3. Update lifespan handler:
   - REMOVE: `await cleanup_stale_instances()`
   - REMOVE: `await server_manager.cleanup()` from shutdown section

4. Remove or update any RunningInstance database operations:
   - The RunningInstance model tracked subprocess PIDs
   - Consider if this model is still needed or can be deprecated

5. Verify no other references to server_manager remain in main.py
  </action>
  <verify>
- `grep "server_manager" backend/mlx_manager/main.py` returns nothing
- `cd backend && python -c "from mlx_manager.main import app"` imports without error
- Server starts without errors: `uvicorn mlx_manager.main:app --port 8080`
  </verify>
  <done>main.py cleaned of server_manager references</done>
</task>

</tasks>

<verification>
After completing all tasks:

1. Verify deletions:
   ```bash
   ls backend/mlx_manager/services/server_manager.py  # Should not exist
   ls backend/mlx_manager/utils/command_builder.py    # Should not exist
   ls backend/mlx_manager/services/parser_options.py  # Should not exist
   ```

2. Verify no broken imports:
   ```bash
   cd backend && python -c "import mlx_manager; print('OK')"
   ```

3. Verify grep for legacy references:
   ```bash
   grep -r "mlx-openai-server" backend/mlx_manager/ || echo "No references found"
   grep -r "server_manager" backend/mlx_manager/ || echo "No references found"
   grep -r "command_builder" backend/mlx_manager/ || echo "No references found"
   grep -r "parser_options" backend/mlx_manager/ || echo "No references found"
   ```

4. Run tests (some may fail and need updating in Plan 05):
   ```bash
   cd backend && pytest tests/test_main.py -v
   ```
</verification>

<success_criteria>
- server_manager.py, command_builder.py, parser_options.py deleted
- No import errors in mlx_manager package
- No references to mlx-openai-server subprocess management remain
- Servers router works with embedded model
</success_criteria>

<output>
After completion, create `.planning/phases/13-mlx-server-integration/13-02-SUMMARY.md`
</output>
