---
phase: 13-mlx-server-integration
plan: 04
type: execute
wave: 2
depends_on: ["13-01"]
files_modified:
  - backend/mlx_manager/routers/settings.py
  - backend/mlx_manager/mlx_server/models/pool.py
  - backend/mlx_manager/mlx_server/services/cloud/router.py
autonomous: true

must_haves:
  truths:
    - "Model Pool Settings changes update the embedded server's model pool"
    - "Cloud Provider Settings connect to the embedded server's routing"
    - "Memory limit changes affect actual memory management"
    - "Preload models actually load in the model pool"
    - "Cloud routing rule changes take effect immediately"
  artifacts:
    - path: "backend/mlx_manager/routers/settings.py"
      provides: "Settings that apply to embedded server"
      contains: "get_model_pool"
    - path: "backend/mlx_manager/mlx_server/models/pool.py"
      provides: "Dynamic configuration support"
      contains: "update_config"
  key_links:
    - from: "backend/mlx_manager/routers/settings.py"
      to: "backend/mlx_manager/mlx_server/models/pool.py"
      via: "direct pool configuration"
      pattern: "model_pool\\.update"
    - from: "backend/mlx_manager/routers/settings.py"
      to: "backend/mlx_manager/mlx_server/services/cloud/router.py"
      via: "cache invalidation on rule update"
      pattern: "backend_router\\.refresh_rules"
---

<objective>
Wire Settings to embedded MLX Server configuration

Purpose: Make the Model Pool Settings and Cloud Provider Settings actually control the embedded server's behavior rather than storing configuration that was never used.

Output: Settings changes immediately affect the running embedded server - memory limits, preload models, and cloud routing rules.
</objective>

<execution_context>
@.claude/get-shit-done/workflows/execute-plan.md
@.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@backend/mlx_manager/routers/settings.py
@backend/mlx_manager/mlx_server/models/pool.py
@backend/mlx_manager/mlx_server/services/cloud/router.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dynamic configuration to ModelPoolManager</name>
  <files>backend/mlx_manager/mlx_server/models/pool.py</files>
  <action>
Add methods to ModelPoolManager for runtime configuration updates:

1. Add `update_memory_limit(self, memory_gb: float = None, memory_pct: float = None)`:
   ```python
   def update_memory_limit(
       self,
       memory_gb: float | None = None,
       memory_pct: float | None = None
   ) -> None:
       """Update memory limit at runtime.

       Args:
           memory_gb: Absolute memory limit in GB
           memory_pct: Memory limit as percentage of system memory (0.0-1.0)
       """
       if memory_pct is not None:
           self._memory_limit_pct = memory_pct
           self.max_memory_gb = self._get_effective_memory_limit()
       elif memory_gb is not None:
           self._memory_limit_pct = None
           self.max_memory_gb = memory_gb

       # Update MLX memory limit
       from mlx_manager.mlx_server.utils.memory import set_memory_limit
       set_memory_limit(self.max_memory_gb)

       logger.info(f"Memory limit updated to {self.max_memory_gb:.1f}GB")
   ```

2. Add `update_max_models(self, max_models: int)`:
   ```python
   def update_max_models(self, max_models: int) -> None:
       """Update maximum hot models at runtime."""
       self.max_models = max_models
       logger.info(f"Max models updated to {max_models}")
   ```

3. Add async `apply_preload_list(self, model_ids: list[str])`:
   ```python
   async def apply_preload_list(self, model_ids: list[str]) -> dict[str, str]:
       """Preload specified models, unload others.

       Returns dict of model_id -> status ('loaded', 'failed', 'already_loaded')
       """
       results = {}

       # Preload new models
       for model_id in model_ids:
           if self.is_loaded(model_id):
               self._models[model_id].preloaded = True
               results[model_id] = "already_loaded"
           else:
               try:
                   await self.preload_model(model_id)
                   results[model_id] = "loaded"
               except Exception as e:
                   logger.error(f"Failed to preload {model_id}: {e}")
                   results[model_id] = f"failed: {e}"

       # Mark models not in preload list as evictable
       for model_id, loaded in self._models.items():
           if model_id not in model_ids:
               loaded.preloaded = False

       return results
   ```

4. Add `get_status(self)` method for status reporting:
   ```python
   def get_status(self) -> dict:
       """Get current pool status."""
       return {
           "max_memory_gb": self.max_memory_gb,
           "current_memory_gb": self._current_memory_gb(),
           "max_models": self.max_models,
           "loaded_models": [
               {
                   "model_id": m.model_id,
                   "size_gb": m.size_gb,
                   "preloaded": m.preloaded,
                   "last_used": m.last_used,
               }
               for m in self._models.values()
           ],
       }
   ```
  </action>
  <verify>
All four new methods must be tested:

1. update_memory_limit:
   ```bash
   cd backend && python -c "
   from mlx_manager.mlx_server.models.pool import ModelPoolManager
   p = ModelPoolManager()
   p.update_memory_limit(memory_gb=24)
   print(f'Memory limit: {p.max_memory_gb}GB')
   assert p.max_memory_gb == 24, 'update_memory_limit failed'
   print('update_memory_limit: OK')
   "
   ```

2. update_max_models:
   ```bash
   cd backend && python -c "
   from mlx_manager.mlx_server.models.pool import ModelPoolManager
   p = ModelPoolManager()
   p.update_max_models(5)
   assert p.max_models == 5, 'update_max_models failed'
   print('update_max_models: OK')
   "
   ```

3. apply_preload_list (async):
   ```bash
   cd backend && python -c "
   import asyncio
   from mlx_manager.mlx_server.models.pool import ModelPoolManager
   p = ModelPoolManager()
   result = asyncio.run(p.apply_preload_list([]))
   print(f'apply_preload_list result: {result}')
   print('apply_preload_list: OK')
   "
   ```

4. get_status:
   ```bash
   cd backend && python -c "
   from mlx_manager.mlx_server.models.pool import ModelPoolManager
   p = ModelPoolManager()
   status = p.get_status()
   assert 'max_memory_gb' in status, 'get_status missing max_memory_gb'
   assert 'loaded_models' in status, 'get_status missing loaded_models'
   print(f'Status: {status}')
   print('get_status: OK')
   "
   ```

- No import errors on any of the above
  </verify>
  <done>ModelPoolManager supports runtime configuration updates with all four methods</done>
</task>

<task type="auto">
  <name>Task 2: Wire settings router to model pool with cache invalidation</name>
  <files>backend/mlx_manager/routers/settings.py</files>
  <action>
Update settings.py pool endpoints to actually apply changes to the embedded server:

1. Import model pool and cloud router:
   ```python
   from mlx_manager.mlx_server.models.pool import get_model_pool
   from mlx_manager.mlx_server.services.cloud.router import backend_router
   ```

2. Update `get_pool_config()` endpoint:
   - In addition to database config, include live pool status
   - Add current memory usage, loaded models count

3. Update `update_pool_config()` endpoint:
   - After saving to database, apply changes to the running pool:
   ```python
   @router.put("/pool", response_model=ServerConfigResponse)
   async def update_pool_config(
       current_user: Annotated[User, Depends(get_current_user)],
       data: ServerConfigUpdate,
       session: AsyncSession = Depends(get_db),
   ):
       # ... existing database update code ...

       # Apply changes to running pool
       try:
           pool = get_model_pool()

           # Update memory limit
           if data.memory_limit_value is not None:
               if config.memory_limit_mode == "percent":
                   pool.update_memory_limit(memory_pct=data.memory_limit_value / 100)
               else:  # "gb"
                   pool.update_memory_limit(memory_gb=data.memory_limit_value)

           # Apply preload list
           if data.preload_models is not None:
               preload_result = await pool.apply_preload_list(data.preload_models)
               logger.info(f"Preload result: {preload_result}")

       except RuntimeError:
           # Pool not initialized (shouldn't happen in embedded mode)
           logger.warning("Model pool not initialized, settings saved but not applied")

       return ServerConfigResponse(...)
   ```

4. Add new endpoint for pool status:
   ```python
   @router.get("/pool/status")
   async def get_pool_status(
       current_user: Annotated[User, Depends(get_current_user)],
   ):
       """Get live model pool status."""
       try:
           pool = get_model_pool()
           return pool.get_status()
       except RuntimeError:
           return {"status": "not_initialized"}
   ```

5. Update cloud provider/routing rule endpoints to invalidate cache:
   - MANDATORY: After any CloudCredential or BackendMapping update:
   ```python
   @router.put("/rules/{rule_id}")
   async def update_routing_rule(
       rule_id: int,
       data: RoutingRuleUpdate,
       session: AsyncSession = Depends(get_db),
       current_user: Annotated[User, Depends(get_current_user)],
   ):
       # ... existing database update code ...

       # MANDATORY: Invalidate cache so rules take effect immediately
       await backend_router.refresh_rules()

       return updated_rule

   @router.post("/providers")
   async def create_provider(...):
       # ... create provider ...
       await backend_router.refresh_rules()  # Refresh after provider changes too
       return provider
   ```
  </action>
  <verify>
- `cd backend && python -c "from mlx_manager.routers.settings import router"` imports without error
- No syntax errors in the file
- `grep "backend_router.refresh_rules" backend/mlx_manager/routers/settings.py` returns at least 1 match
- PUT /api/settings/pool endpoint calls pool.update_memory_limit
  </verify>
  <done>Settings router applies changes to embedded server with immediate cache invalidation</done>
</task>

<task type="auto">
  <name>Task 3: Add refresh_rules to cloud router</name>
  <files>backend/mlx_manager/mlx_server/services/cloud/router.py</files>
  <action>
Add cache invalidation method to BackendRouter:

1. Add `refresh_rules()` async method to invalidate cached routing rules:
   ```python
   async def refresh_rules(self) -> None:
       """Reload routing rules from database. Call after rule/credential updates."""
       # Clear any cached rules
       self._cached_rules = None
       self._cache_timestamp = None

       # Force reload from database
       async with get_db() as session:
           self._rules = await self._load_rules_from_db(session)

       logger.info(f"Routing rules refreshed: {len(self._rules)} rules loaded")
   ```

2. If BackendRouter uses TTL-based caching, ensure refresh_rules() resets it:
   ```python
   def _is_cache_valid(self) -> bool:
       if self._cache_timestamp is None:
           return False
       return (time.time() - self._cache_timestamp) < self._cache_ttl

   async def refresh_rules(self) -> None:
       """Force cache invalidation and reload."""
       self._cache_timestamp = None  # Invalidate TTL
       await self._reload_rules()
   ```

3. Ensure the router uses shared database session:
   - Import `get_db` from mlx_manager.database (not mlx_server.database)
   - This ensures rules saved via MLX Manager settings are visible

4. Export backend_router singleton for import by settings router:
   ```python
   # At module level
   backend_router = BackendRouter()

   # In __all__
   __all__ = ["BackendRouter", "backend_router"]
   ```

Note: The key goal is that changes made via /api/settings/rules endpoints IMMEDIATELY affect routing behavior in the embedded MLX Server without requiring restart.
  </action>
  <verify>
- `cd backend && python -c "from mlx_manager.mlx_server.services.cloud.router import backend_router; import asyncio; asyncio.run(backend_router.refresh_rules())"` runs without error
- `grep "async def refresh_rules" backend/mlx_manager/mlx_server/services/cloud/router.py` returns 1 match
- Cloud routing rules created via API affect actual request routing (requires integration test)
  </verify>
  <done>Cloud router supports immediate cache invalidation via refresh_rules()</done>
</task>

</tasks>

<verification>
After completing all tasks:

1. Start the server:
   ```bash
   cd backend && uvicorn mlx_manager.main:app --port 8080
   ```

2. Test pool configuration:
   ```bash
   # Get current pool status
   curl -H "Authorization: Bearer $TOKEN" http://localhost:8080/api/settings/pool/status

   # Update memory limit
   curl -X PUT -H "Authorization: Bearer $TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"memory_limit_mode": "gb", "memory_limit_value": 24}' \
     http://localhost:8080/api/settings/pool

   # Verify change applied
   curl -H "Authorization: Bearer $TOKEN" http://localhost:8080/api/settings/pool/status
   ```

3. Test preload models:
   ```bash
   # Set preload list (requires model to be downloaded)
   curl -X PUT -H "Authorization: Bearer $TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"preload_models": ["mlx-community/Qwen3-0.6B-4bit"]}' \
     http://localhost:8080/api/settings/pool

   # Verify model loaded
   curl -H "Authorization: Bearer $TOKEN" http://localhost:8080/api/settings/pool/status
   ```

4. Test cloud routing with immediate effect:
   - Create a routing rule via API
   - Verify refresh_rules was called (check logs for "Routing rules refreshed")
   - Make a chat request that matches the rule
   - Verify request routes to cloud provider immediately (no restart needed)
</verification>

<success_criteria>
- Memory limit changes take immediate effect on model pool
- Preload models setting actually loads models
- Cloud routing rules affect request routing immediately (no restart)
- Pool status endpoint shows live information
- refresh_rules() called after every rule/credential update
</success_criteria>

<output>
After completion, create `.planning/phases/13-mlx-server-integration/13-04-SUMMARY.md`
</output>
