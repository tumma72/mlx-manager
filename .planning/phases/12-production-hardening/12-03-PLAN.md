---
phase: 12-production-hardening
plan: 03
type: execute
wave: 2
depends_on: ["12-02"]
files_modified:
  - backend/mlx_manager/mlx_server/middleware/__init__.py
  - backend/mlx_manager/mlx_server/middleware/timeout.py
  - backend/mlx_manager/mlx_server/api/v1/chat.py
  - backend/mlx_manager/mlx_server/api/v1/completions.py
  - backend/mlx_manager/mlx_server/api/v1/embeddings.py
  - backend/mlx_manager/mlx_server/config.py
  - backend/tests/mlx_server/test_timeout.py
autonomous: true

must_haves:
  truths:
    - "Chat completions timeout after 15 minutes by default"
    - "Completions endpoint times out after 10 minutes by default"
    - "Embeddings endpoint times out after 2 minutes by default"
    - "Timeout raises TimeoutHTTPException with proper Problem Details"
    - "Timeouts are configurable via settings"
  artifacts:
    - path: "backend/mlx_manager/mlx_server/middleware/timeout.py"
      provides: "Timeout decorator using asyncio.wait_for"
      exports: ["with_timeout"]
    - path: "backend/mlx_manager/mlx_server/config.py"
      provides: "Timeout settings per endpoint type"
      contains: "timeout_chat_seconds"
  key_links:
    - from: "api/v1/chat.py"
      to: "middleware/timeout.py"
      via: "with_timeout decorator on endpoint"
      pattern: "@with_timeout"
    - from: "middleware/timeout.py"
      to: "errors/problem_details.py"
      via: "TimeoutHTTPException import"
      pattern: "TimeoutHTTPException"
---

<objective>
Implement per-endpoint configurable timeouts

Purpose: PROD-03 requires configurable timeouts. Per 12-CONTEXT.md user decisions:
- **Timeout tiers:** Per endpoint type (Chat: 15 min, Completions: 10 min, Embeddings: 2 min)
- **Cloud vs local:** Same timeouts per endpoint (no separate cloud timeouts needed)
- **Per-request control:** No (admin-configured defaults only)
- **Partial response on timeout:** Discard (timeout = error, no partial content)

NOTE: The original PROD-03 requirement mentioned "per-backend timeouts" but the user clarified in 12-CONTEXT.md that per-endpoint timeouts apply equally to both local and cloud backends. This is the correct implementation.

Output: All inference endpoints have timeouts using asyncio.wait_for with TimeoutHTTPException
</objective>

<execution_context>
@.claude/get-shit-done/workflows/execute-plan.md
@.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-production-hardening/12-CONTEXT.md
@.planning/phases/12-production-hardening/12-RESEARCH.md
@backend/mlx_manager/mlx_server/config.py
@backend/mlx_manager/mlx_server/api/v1/chat.py
@backend/mlx_manager/mlx_server/api/v1/completions.py
@backend/mlx_manager/mlx_server/api/v1/embeddings.py
@backend/mlx_manager/mlx_server/errors/problem_details.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add timeout settings to config and create timeout decorator</name>
  <files>
    backend/mlx_manager/mlx_server/config.py
    backend/mlx_manager/mlx_server/middleware/__init__.py
    backend/mlx_manager/mlx_server/middleware/timeout.py
  </files>
  <action>
1. Update `mlx_server/config.py` to add timeout settings:
   ```python
   # Timeout settings (seconds) - per CONTEXT.md decisions
   # Same timeouts apply to both local and cloud backends
   timeout_chat_seconds: float = Field(
       default=900.0,  # 15 minutes
       description="Timeout for /v1/chat/completions endpoint",
   )
   timeout_completions_seconds: float = Field(
       default=600.0,  # 10 minutes
       description="Timeout for /v1/completions endpoint",
   )
   timeout_embeddings_seconds: float = Field(
       default=120.0,  # 2 minutes
       description="Timeout for /v1/embeddings endpoint",
   )
   ```

2. Create `backend/mlx_manager/mlx_server/middleware/__init__.py`:
   ```python
   """Middleware components for MLX Server."""

   from mlx_manager.mlx_server.middleware.timeout import with_timeout

   __all__ = ["with_timeout"]
   ```

3. Create `backend/mlx_manager/mlx_server/middleware/timeout.py`:
   ```python
   """Timeout decorator for async endpoints.

   Uses asyncio.wait_for to enforce per-endpoint timeouts.
   Per CONTEXT.md: Timeout = error, discard partial response.
   Same timeouts apply to both local and cloud backends.
   """

   import asyncio
   import logging
   from collections.abc import Awaitable, Callable
   from functools import wraps
   from typing import ParamSpec, TypeVar

   from mlx_manager.mlx_server.errors.problem_details import TimeoutHTTPException

   logger = logging.getLogger(__name__)

   P = ParamSpec("P")
   T = TypeVar("T")


   def with_timeout(seconds: float) -> Callable[[Callable[P, Awaitable[T]]], Callable[P, Awaitable[T]]]:
       """Decorator to add timeout to async endpoint.

       Args:
           seconds: Timeout in seconds. If exceeded, raises TimeoutHTTPException.

       Returns:
           Decorator that wraps the endpoint with asyncio.wait_for.

       Example:
           @router.post("/v1/chat/completions")
           @with_timeout(900.0)  # 15 minutes
           async def create_chat_completion(request: ChatCompletionRequest):
               ...
       """

       def decorator(func: Callable[P, Awaitable[T]]) -> Callable[P, Awaitable[T]]:
           @wraps(func)
           async def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:
               try:
                   return await asyncio.wait_for(
                       func(*args, **kwargs),
                       timeout=seconds,
                   )
               except asyncio.TimeoutError:
                   logger.warning(
                       f"Endpoint {func.__name__} timed out after {seconds}s"
                   )
                   raise TimeoutHTTPException(
                       timeout_seconds=seconds,
                       detail=f"Request timed out after {int(seconds)} seconds. "
                              f"Consider using a smaller model or reducing max_tokens.",
                   )

           return wrapper

       return decorator


   def get_timeout_for_endpoint(endpoint: str) -> float:
       """Get configured timeout for an endpoint type.

       Args:
           endpoint: Endpoint path (e.g., "/v1/chat/completions")

       Returns:
           Timeout in seconds from settings.
       """
       from mlx_manager.mlx_server.config import get_settings

       settings = get_settings()

       if "chat" in endpoint:
           return settings.timeout_chat_seconds
       elif "completions" in endpoint:
           return settings.timeout_completions_seconds
       elif "embeddings" in endpoint:
           return settings.timeout_embeddings_seconds
       else:
           # Default to chat timeout for unknown endpoints
           return settings.timeout_chat_seconds
   ```
  </action>
  <verify>
    - `grep "timeout_chat_seconds" backend/mlx_manager/mlx_server/config.py`
    - `python -c "from mlx_manager.mlx_server.middleware.timeout import with_timeout; print('OK')"`
    - `python -c "from mlx_manager.mlx_server.config import get_settings; s = get_settings(); print(f'Chat: {s.timeout_chat_seconds}s, Completions: {s.timeout_completions_seconds}s, Embeddings: {s.timeout_embeddings_seconds}s')"`
  </verify>
  <done>Timeout decorator and settings exist with correct defaults</done>
</task>

<task type="auto">
  <name>Task 2: Apply timeouts to inference endpoints</name>
  <files>
    backend/mlx_manager/mlx_server/api/v1/chat.py
    backend/mlx_manager/mlx_server/api/v1/completions.py
    backend/mlx_manager/mlx_server/api/v1/embeddings.py
  </files>
  <action>
The timeout decorator needs to wrap the INNER async functions that do the actual work, not the endpoint directly (since streaming returns EventSourceResponse immediately).

1. Update `api/v1/chat.py`:
   - Import the timeout function: `from mlx_manager.mlx_server.config import get_settings`
   - For NON-STREAMING requests, wrap the work in asyncio.wait_for
   - For STREAMING requests, the timeout happens within the generator

   The cleanest approach is to add timeout handling inside `_handle_direct_request` and `_handle_routed_request` for the non-streaming case:

   ```python
   # In _handle_non_streaming function:
   import asyncio
   from mlx_manager.mlx_server.errors import TimeoutHTTPException

   async def _handle_non_streaming(...) -> ChatCompletionResponse:
       settings = get_settings()
       try:
           result = await asyncio.wait_for(
               generate_chat_completion(...),
               timeout=settings.timeout_chat_seconds,
           )
       except asyncio.TimeoutError:
           raise TimeoutHTTPException(
               timeout_seconds=settings.timeout_chat_seconds,
               detail=f"Chat completion timed out after {int(settings.timeout_chat_seconds)} seconds",
           )
       # ... rest of function
   ```

   For streaming, add timeout to the generator:
   ```python
   async def _handle_streaming(...) -> EventSourceResponse:
       async def event_generator() -> Any:
           settings = get_settings()
           try:
               gen = await asyncio.wait_for(
                   generate_chat_completion(..., stream=True),
                   timeout=settings.timeout_chat_seconds,
               )
               async for chunk in gen:
                   yield {"data": json.dumps(chunk)}
               yield {"data": "[DONE]"}
           except asyncio.TimeoutError:
               # Send error event before closing (per CONTEXT.md streaming errors)
               error_event = {
                   "error": {
                       "type": "timeout",
                       "message": f"Request timed out after {int(settings.timeout_chat_seconds)} seconds",
                   }
               }
               yield {"event": "error", "data": json.dumps(error_event)}

       return EventSourceResponse(event_generator())
   ```

2. Update `api/v1/completions.py`:
   - Same pattern with `settings.timeout_completions_seconds`

3. Update `api/v1/embeddings.py`:
   - Embeddings are non-streaming, simpler case
   - Wrap the embedding generation call in asyncio.wait_for
   - Use `settings.timeout_embeddings_seconds`
  </action>
  <verify>
    - `grep -r "asyncio.wait_for" backend/mlx_manager/mlx_server/api/v1/chat.py`
    - `grep -r "asyncio.wait_for" backend/mlx_manager/mlx_server/api/v1/completions.py`
    - `grep -r "asyncio.wait_for" backend/mlx_manager/mlx_server/api/v1/embeddings.py`
    - `grep -r "TimeoutHTTPException" backend/mlx_manager/mlx_server/api/v1/`
  </verify>
  <done>All inference endpoints have timeout handling</done>
</task>

<task type="auto">
  <name>Task 3: Add timeout tests</name>
  <files>
    backend/tests/mlx_server/test_timeout.py
  </files>
  <action>
Create `backend/tests/mlx_server/test_timeout.py`:

```python
"""Tests for endpoint timeout functionality."""

import asyncio

import pytest

from mlx_manager.mlx_server.errors import TimeoutHTTPException
from mlx_manager.mlx_server.middleware.timeout import with_timeout


class TestWithTimeoutDecorator:
    """Test the with_timeout decorator."""

    @pytest.mark.asyncio
    async def test_fast_function_succeeds(self) -> None:
        """Function completing before timeout returns normally."""

        @with_timeout(1.0)
        async def fast_function() -> str:
            await asyncio.sleep(0.01)
            return "success"

        result = await fast_function()
        assert result == "success"

    @pytest.mark.asyncio
    async def test_slow_function_raises_timeout(self) -> None:
        """Function exceeding timeout raises TimeoutHTTPException."""

        @with_timeout(0.05)
        async def slow_function() -> str:
            await asyncio.sleep(1.0)
            return "never returned"

        with pytest.raises(TimeoutHTTPException) as exc_info:
            await slow_function()

        assert exc_info.value.status_code == 408
        assert exc_info.value.timeout_seconds == 0.05
        assert "timed out" in str(exc_info.value.detail).lower()

    @pytest.mark.asyncio
    async def test_preserves_function_metadata(self) -> None:
        """Decorated function preserves name and docstring."""

        @with_timeout(1.0)
        async def documented_function() -> str:
            """This is a docstring."""
            return "ok"

        assert documented_function.__name__ == "documented_function"
        assert documented_function.__doc__ == "This is a docstring."

    @pytest.mark.asyncio
    async def test_exception_propagates(self) -> None:
        """Non-timeout exceptions propagate normally."""

        @with_timeout(1.0)
        async def raising_function() -> str:
            raise ValueError("test error")

        with pytest.raises(ValueError, match="test error"):
            await raising_function()


class TestTimeoutSettings:
    """Test timeout configuration."""

    def test_default_timeouts(self) -> None:
        """Default timeouts match CONTEXT.md decisions."""
        from mlx_manager.mlx_server.config import get_settings

        # Clear cache to get fresh settings
        get_settings.cache_clear()
        settings = get_settings()

        assert settings.timeout_chat_seconds == 900.0  # 15 minutes
        assert settings.timeout_completions_seconds == 600.0  # 10 minutes
        assert settings.timeout_embeddings_seconds == 120.0  # 2 minutes

    def test_get_timeout_for_endpoint(self) -> None:
        """get_timeout_for_endpoint returns correct timeout."""
        from mlx_manager.mlx_server.middleware.timeout import get_timeout_for_endpoint

        assert get_timeout_for_endpoint("/v1/chat/completions") == 900.0
        assert get_timeout_for_endpoint("/v1/completions") == 600.0
        assert get_timeout_for_endpoint("/v1/embeddings") == 120.0
```
  </action>
  <verify>
    - `cd backend && pytest tests/mlx_server/test_timeout.py -v`
  </verify>
  <done>Timeout decorator and settings are tested</done>
</task>

</tasks>

<verification>
Run timeout tests:
```bash
cd backend && source .venv/bin/activate
pytest tests/mlx_server/test_timeout.py -v
```

Run full MLX server test suite:
```bash
pytest tests/mlx_server/ -v
```

Verify settings work with environment override:
```bash
MLX_SERVER_TIMEOUT_CHAT_SECONDS=60 python -c "
from mlx_manager.mlx_server.config import MLXServerSettings
s = MLXServerSettings()
print(f'Chat timeout: {s.timeout_chat_seconds}s')
assert s.timeout_chat_seconds == 60.0
print('OK')
"
```
</verification>

<success_criteria>
- Timeout settings exist with correct defaults (Chat: 900s, Completions: 600s, Embeddings: 120s)
- with_timeout decorator raises TimeoutHTTPException on timeout
- All inference endpoints have timeout handling
- Streaming endpoints send error event on timeout
- Timeouts are configurable via environment variables
- All timeout tests pass
- Same timeouts apply to both local and cloud backends (per CONTEXT.md)
</success_criteria>

<output>
After completion, create `.planning/phases/12-production-hardening/12-03-SUMMARY.md`
</output>
