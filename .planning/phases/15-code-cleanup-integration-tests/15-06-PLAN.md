# Plan 15-06: Fix Vision Model Detection & Loading

## Objective

Fix the mismatch between frontend Vision badge display and backend model type detection, ensuring Gemma and other vision models are correctly detected and loaded.

## Problem Statement

**The contradiction:**
- Frontend shows Vision badge (characteristics detection reads config.json → sees `vision_config`)
- MLX Server detects as TEXT_GEN (config fails to load → falls back to name patterns → "gemma" missing)

**Error chain:**
1. Gemma detected as TEXT_GEN at load time
2. Loaded with mlx-lm (gets Tokenizer)
3. User sends image → routes to vision.py
4. vision.py uses mlx-vlm functions expecting Processor
5. Crash: "processor does not have 'chat_template'"

## Tasks

### Task 1: Add Gemma to vision name patterns

**File:** `backend/mlx_manager/mlx_server/models/detection.py`

Update line 70 to include Gemma 3 multimodal patterns:

```python
# Current:
vision_patterns = ("-vl", "vlm", "vision", "qwen2-vl", "qwen2.5-vl", "llava", "pixtral")

# Updated:
vision_patterns = (
    "-vl", "vlm", "vision",
    "qwen2-vl", "qwen2.5-vl",
    "llava", "pixtral",
    "gemma-3",  # Gemma 3 multimodal (gemma-3-*-it models)
)
```

### Task 2: Improve config loading reliability

**File:** `backend/mlx_manager/mlx_server/models/detection.py`

Add better error handling and logging when config loading fails:

```python
def detect_model_type(model_id: str, config: dict[str, Any] | None = None) -> ModelType:
    # Try to load config if not provided
    if config is None:
        try:
            from mlx_manager.utils.model_detection import read_model_config
            config = read_model_config(model_id)
            logger.debug(f"Loaded config for {model_id}: keys={list(config.keys()) if config else 'None'}")
        except Exception as e:
            logger.warning(f"Could not load config for {model_id}: {e}")
            config = None

    # ... rest of detection
```

### Task 3: Add graceful handling for detection/loading mismatch

**File:** `backend/mlx_manager/routers/chat.py`

When vision request comes in but model wasn't loaded as vision, provide clear error:

```python
if has_images:
    # Check if model was actually loaded as vision type
    from mlx_manager.mlx_server.models.pool import get_model_pool

    pool = get_model_pool()
    loaded = pool._models.get(model_id)

    if loaded and loaded.model_type != "vision":
        raise HTTPException(
            status_code=400,
            detail=f"Model {model_id} was loaded as {loaded.model_type}, "
                   f"but image input requires a vision model. "
                   f"Please unload and reload the model, or use a vision-capable model."
        )
```

### Task 4: Synchronize detection logic

**Files:**
- `backend/mlx_manager/utils/model_detection.py` (characteristics for badges)
- `backend/mlx_manager/mlx_server/models/detection.py` (loading type)

Ensure both use the same detection logic by having MLX server detection call the shared utility:

```python
# In mlx_server/models/detection.py
from mlx_manager.utils.model_detection import detect_multimodal, read_model_config

def detect_model_type(model_id: str, config: dict[str, Any] | None = None) -> ModelType:
    if config is None:
        config = read_model_config(model_id) or {}

    # Use shared detection
    is_multimodal, multimodal_type = detect_multimodal(config)
    if is_multimodal and multimodal_type == "vision":
        return ModelType.VISION

    # ... embeddings detection etc.
```

### Task 5: Add model reload capability (optional enhancement)

**File:** `backend/mlx_manager/mlx_server/models/pool.py`

Add method to reload a model with different type:

```python
async def reload_as_type(self, model_id: str, model_type: ModelType) -> LoadedModel:
    """Unload and reload a model with a specific type.

    Useful when detection was wrong and model needs to be reloaded
    as vision instead of text-gen.
    """
    await self.unload(model_id)
    return await self._load_model_as_type(model_id, model_type)
```

## Success Criteria

1. [ ] Gemma-3 multimodal models detected as VISION type
2. [ ] Config loading logs helpful debug info on failure
3. [ ] Clear error message when vision request hits non-vision model
4. [ ] Badge detection and loading detection use same logic
5. [ ] Gemma vision model can process images without crashing

## Test Scenarios

1. Load `mlx-community/gemma-3-27b-it-4bit-DWQ` → should detect as VISION
2. Send image to Gemma → should work without error
3. Send image to non-vision model → should get clear error message
4. Frontend badge matches server-side detection

## Dependencies

- Plan 15-05 (unload functionality for reload)

## Estimated Complexity

Medium - Detection logic fixes plus error handling

---

*Plan: 15-06*
*Phase: 15-code-cleanup-integration-tests*
*Priority: HIGH*
