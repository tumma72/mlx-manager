---
task: 15-08
title: Profile Model Cleanup - Remove Obsolete Fields
status: planned
priority: medium
estimated_effort: medium
---

## Goal

Clean up the ServerProfile model by removing fields that are no longer needed with the embedded MLX server, and add new generation parameter fields.

## Context

The profile form still contains fields from when mlx-openai-server was used as a separate backend. With the embedded server, many of these fields are obsolete. Additionally, generation parameters (temperature, max_tokens, top_p) should be configurable per profile.

## Changes Required

### 1. Backend Model Changes (`backend/mlx_manager/models.py`)

**Fields to REMOVE from ServerProfileBase:**
- `port: int` - No longer running separate servers
- `host: str` - Always localhost with embedded server
- `max_concurrency: int` - Not applicable
- `queue_timeout: int` - Not applicable
- `queue_size: int` - Not applicable
- `tool_call_parser: str | None` - Handled by adapters
- `reasoning_parser: str | None` - Handled by adapters
- `message_converter: str | None` - Handled by adapters
- `enable_auto_tool_choice: bool` - Not used
- `trust_remote_code: bool` - Handled by mlx-lm
- `chat_template_file: str | None` - Handled by tokenizer
- `log_level: str` - Server-level setting
- `log_file: str | None` - Server-level setting
- `no_log_file: bool` - Server-level setting

**Fields to ADD to ServerProfileBase:**
- `temperature: float = Field(default=0.7)` - Generation temperature (0.0-2.0)
- `max_tokens: int = Field(default=4096)` - Maximum tokens to generate
- `top_p: float = Field(default=1.0)` - Nucleus sampling (0.0-1.0)

**Also update:**
- `ServerProfileUpdate` schema
- `ServerProfileResponse` schema

### 2. Database Migration

Create Alembic migration to:
- Drop obsolete columns
- Add new columns with defaults

### 3. Backend Router Changes (`backend/mlx_manager/routers/chat.py`)

Update to use profile settings:
```python
temp = request.temperature if request.temperature is not None else profile.temperature
max_tok = request.max_tokens if request.max_tokens is not None else profile.max_tokens
```

### 4. Frontend Form Changes

**File:** `frontend/src/routes/(protected)/profiles/[id]/+page.svelte` (and create form)

**Remove from Advanced Options:**
- Host field
- Max Concurrency field
- Queue Timeout field
- Queue Size field
- Model-Specific Parsers section (Tool Call Parser, Reasoning Parser, Message Converter)

**Add to form (new Generation Settings section):**
- Temperature slider (0.0-2.0, step 0.1, default 0.7)
- Max Tokens input (100-32000, default 4096)
- Top P slider (0.0-1.0, step 0.05, default 1.0)

### 5. API Type Updates

**File:** `frontend/src/lib/api/types.ts`

Update `ServerProfile` interface to match new model.

## Testing

- [ ] Existing profiles continue to work (migration preserves data)
- [ ] New profiles can be created with generation settings
- [ ] Generation settings are used in chat completions
- [ ] Request-level overrides take precedence over profile defaults

## Dependencies

- None (can be done independently)

## Risks

- Database migration on existing installations
- Need to handle profiles created before migration
