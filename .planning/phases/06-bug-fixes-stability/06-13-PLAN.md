---
phase: 06-bug-fixes-stability
plan: 13
type: execute
wave: 2
depends_on: [11]
files_modified:
  - frontend/src/routes/(protected)/chat/+page.svelte
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "User can toggle MCP tools on/off in chat UI"
    - "When tools enabled, tools array is sent with chat completions request"
    - "Model tool_calls are displayed as formatted blocks in the assistant message"
    - "Tool calls are auto-executed via mcp.executeTool()"
    - "Tool results are sent back to model as role:tool messages"
    - "Tool-use loop limited to 3 rounds maximum to prevent infinite loops"
    - "Complete tool-use conversation loop works end-to-end"
  artifacts:
    - path: "frontend/src/routes/(protected)/chat/+page.svelte"
      provides: "Tools toggle, tool call display, auto-execution loop with depth limit"
      contains: "toolsEnabled"
  key_links:
    - from: "frontend/src/routes/(protected)/chat/+page.svelte"
      to: "frontend/src/lib/api/client.ts"
      via: "mcp.listTools() on mount, mcp.executeTool() in loop"
      pattern: "mcp\\.(listTools|executeTool)"
    - from: "frontend/src/routes/(protected)/chat/+page.svelte"
      to: "backend/mlx_manager/routers/chat.py"
      via: "tools array in chat request body, tool results in follow-up"
      pattern: "tools.*availableTools"
---

<objective>
Add tool-use UI and execution loop to the chat page. Users toggle tools on/off, tool calls from the model are displayed, auto-executed, and results sent back for the model to continue. The loop has a max depth of 3 to prevent infinite tool-call cycles.

Purpose: Complete the end-to-end tool-use experience in chat
Output: Working tool toggle, tool call display, auto-execution, and multi-round tool loop with safety limit
</objective>

<execution_context>
@.claude/get-shit-done/workflows/execute-plan.md
@.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/06-bug-fixes-stability/06-11-SUMMARY.md
@frontend/src/routes/(protected)/chat/+page.svelte
@frontend/src/lib/api/client.ts
@frontend/src/lib/api/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Tools toggle UI and state</name>
  <files>frontend/src/routes/(protected)/chat/+page.svelte</files>
  <action>
    Add tool loading, state, and toggle button to the chat page.

    **1. Add imports (at the top of the script block):**
    - Add `mcp` to imports from the API client. The existing file imports from `$stores` and `$components/ui`. Add:
      ```typescript
      import { mcp } from '$lib/api/client';
      import { Wrench } from 'lucide-svelte';
      import type { ToolCall, ToolDefinition } from '$lib/api/types';
      ```

    **2. Add component-level state (after the existing state declarations, around line 30):**
    ```typescript
    let toolsEnabled = $state(false);
    let availableTools = $state<ToolDefinition[]>([]);
    let toolsLoaded = $state(false);
    ```

    **3. Load tools in the existing onMount (line 58-68):**
    Add inside the existing `onMount(async () => { ... })` block, after the `serverStore.refresh()` call:
    ```typescript
    // Load available MCP tools
    try {
      availableTools = await mcp.listTools();
      toolsLoaded = true;
    } catch {
      // MCP tools not available - toggle won't show
    }
    ```

    **4. Add toggle button in the chat input form:**
    Find the input bar area (the form with the send button). Add a tools toggle button BEFORE the attach button (the Paperclip button). The button should be inside the same flex container as the other buttons:
    ```svelte
    {#if toolsLoaded}
      <Button
        type="button"
        variant={toolsEnabled ? "default" : "ghost"}
        size="icon"
        onclick={() => toolsEnabled = !toolsEnabled}
        title={toolsEnabled ? `Tools enabled (${availableTools.length})` : "Enable tools"}
      >
        <Wrench class="w-4 h-4" />
      </Button>
    {/if}
    ```
  </action>
  <verify>
    Run: `cd /Users/atomasini/Development/mlx-manager/frontend && npm run check`
    Grep for `toolsEnabled` and `Wrench` in the file to confirm additions.
  </verify>
  <done>
    - toolsEnabled, availableTools, toolsLoaded state variables exist
    - MCP tools loaded on mount via mcp.listTools()
    - Wrench toggle button visible when tools loaded
    - Toggle switches between ghost/default variant
  </done>
</task>

<task type="auto">
  <name>Task 2: Tool-use execution loop with depth limit</name>
  <files>frontend/src/routes/(protected)/chat/+page.svelte</files>
  <action>
    Restructure sendWithRetry to support tool-use loops. The key changes are:
    1. Lift `apiMessages` to be a parameter so it persists across tool rounds
    2. Extract SSE stream reading into a reusable helper
    3. Add tool_call/tool_calls_done handling with auto-execution
    4. Add max depth limit (3 rounds) to prevent infinite loops

    **CRITICAL DESIGN DECISIONS (resolving all blockers):**
    - `apiMessages` is built fresh each call but the tool loop passes the accumulated array to follow-up requests
    - Auth headers use `authStore.token` directly (same pattern as existing code, line 239)
    - SSE reading extracted to `processSSEStream()` helper to avoid duplication
    - Max 3 tool-call rounds per user message (prevents infinite loops)

    **1. Add a helper function `processSSEStream` (above sendWithRetry):**
    This extracts the SSE reading loop so it can be reused for follow-up tool requests:
    ```typescript
    interface StreamResult {
      content: string;
      thinking: string;
      thinkingDur: number | undefined;
      toolCalls: Array<{ id: string; name: string; arguments: string }>;
      toolCallsDone: boolean;
      error: { summary: string; details?: string } | null;
    }

    async function processSSEStream(response: Response): Promise<StreamResult> {
      const result: StreamResult = {
        content: '',
        thinking: '',
        thinkingDur: undefined,
        toolCalls: [],
        toolCallsDone: false,
        error: null,
      };

      const reader = response.body?.getReader();
      if (!reader) return result;

      const decoder = new TextDecoder();
      let buffer = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';

        for (const line of lines) {
          if (!line.startsWith('data: ')) continue;
          try {
            const data = JSON.parse(line.slice(6));
            switch (data.type) {
              case 'thinking':
                result.thinking += data.content;
                streamingThinking += data.content;
                break;
              case 'thinking_done':
                result.thinkingDur = data.duration;
                thinkingDuration = data.duration;
                break;
              case 'response':
                result.content += data.content;
                streamingResponse += data.content;
                break;
              case 'tool_call': {
                const tc = data.tool_call;
                const existing = result.toolCalls.find(t => t.id === tc.id);
                if (existing) {
                  existing.arguments += tc.function?.arguments || '';
                } else if (tc.id) {
                  result.toolCalls.push({
                    id: tc.id,
                    name: tc.function?.name || '',
                    arguments: tc.function?.arguments || '',
                  });
                }
                break;
              }
              case 'tool_calls_done':
                result.toolCallsDone = true;
                break;
              case 'error':
                if (data.content.includes('Failed to connect')) {
                  result.error = { summary: 'Connection failed', details: data.content };
                } else if (data.content.includes('timed out')) {
                  result.error = { summary: 'Request timed out', details: data.content };
                } else {
                  result.error = { summary: 'Server error', details: data.content };
                }
                break;
              case 'done':
                break;
            }
          } catch {
            // Ignore parse errors
          }
        }
      }
      return result;
    }
    ```

    **2. Modify sendWithRetry to use processSSEStream and handle tool loops:**

    Replace the existing SSE reading section (from `const reader = response.body?.getReader()` through the end of the while loop, approximately lines 262-325) with:

    ```typescript
    // Process the SSE stream
    const streamResult = await processSSEStream(response);

    if (streamResult.error) {
      chatError = streamResult.error;
      return false;
    }

    // Handle tool-use loop (max 3 rounds to prevent infinite loops)
    const MAX_TOOL_DEPTH = 3;
    let currentResult = streamResult;
    let toolDepth = 0;
    let assistantContent = currentResult.content;

    while (currentResult.toolCallsDone && currentResult.toolCalls.length > 0 && toolDepth < MAX_TOOL_DEPTH) {
      toolDepth++;

      // Display tool calls in assistant message
      for (const toolCall of currentResult.toolCalls) {
        const toolCallText = `\n\n---\n**Tool call:** \`${toolCall.name}(${toolCall.arguments})\`\n`;
        assistantContent += toolCallText;
        streamingResponse = assistantContent;

        // Execute the tool
        try {
          const parsedArgs = JSON.parse(toolCall.arguments);
          const result = await mcp.executeTool(toolCall.name, parsedArgs);
          const resultText = `**Result:** \`${JSON.stringify(result)}\`\n---\n\n`;
          assistantContent += resultText;
          streamingResponse = assistantContent;

          // Add assistant tool_calls message and tool result to apiMessages
          apiMessages.push({
            role: 'assistant',
            content: '',
            tool_calls: [{
              id: toolCall.id,
              type: 'function',
              function: { name: toolCall.name, arguments: toolCall.arguments }
            }]
          } as any);
          apiMessages.push({
            role: 'tool',
            tool_call_id: toolCall.id,
            content: JSON.stringify(result)
          } as any);
        } catch {
          assistantContent += `**Error:** Tool execution failed\n---\n\n`;
          streamingResponse = assistantContent;
        }
      }

      // Send follow-up request with tool results
      const followUpBody: Record<string, unknown> = {
        profile_id: selectedProfile!.id,
        messages: apiMessages,
      };
      if (toolsEnabled && availableTools.length > 0) {
        followUpBody.tools = availableTools;
        followUpBody.tool_choice = 'auto';
      }

      const followUpRes = await fetch('/api/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${authStore.token}`,
        },
        body: JSON.stringify(followUpBody),
      });

      if (!followUpRes.ok) break;

      // Process follow-up stream (may contain more tool calls)
      currentResult = await processSSEStream(followUpRes);
      assistantContent += currentResult.content;
      streamingResponse = assistantContent;

      if (currentResult.error) {
        chatError = currentResult.error;
        break;
      }
    }

    // If we hit max depth and model still wants tools, show warning
    if (toolDepth >= MAX_TOOL_DEPTH && currentResult.toolCallsDone) {
      assistantContent += '\n\n*[Tool call limit reached (3 rounds). Stopping automatic execution.]*';
      streamingResponse = assistantContent;
    }
    ```

    **3. Update the "done" finalization (the existing `case 'done':` block is now handled differently):**
    After the tool loop (or if no tool calls), finalize the message. Replace the old finalization code (lines 313-318 that check `streamingResponse || streamingThinking`) with:

    ```typescript
    // Finalize assistant message
    const finalContent = streamingThinking
      ? `<think>${streamingThinking}</think>${streamingResponse}`
      : streamingResponse;
    if (finalContent) {
      messages.push({ role: 'assistant', content: finalContent });
    }
    ```

    This should remain in the same position (after stream processing, before the success return).

    **4. Modify the request body to include tools:**
    In the fetch call body (around line 241-244), change from inline object to variable:
    ```typescript
    const requestBody: Record<string, unknown> = {
      profile_id: selectedProfile.id,
      messages: apiMessages,
    };
    if (toolsEnabled && availableTools.length > 0) {
      requestBody.tools = availableTools;
      requestBody.tool_choice = 'auto';
    }

    const response = await fetch('/api/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${authStore.token}`,
      },
      body: JSON.stringify(requestBody),
    });
    ```

    **IMPORTANT SCOPING NOTE:** The `apiMessages` array is built at the top of `sendWithRetry` (line 219). It remains in scope throughout the function body including the tool loop. The tool loop mutates it by pushing assistant/tool messages. This is correct because the follow-up requests need the accumulated conversation history.
  </action>
  <verify>
    Run: `cd /Users/atomasini/Development/mlx-manager/frontend && npm run check && npm run lint`
    Verify no TypeScript errors. Grep for `MAX_TOOL_DEPTH`, `processSSEStream`, `toolCallsDone`, `mcp.executeTool` to confirm all pieces are present.
  </verify>
  <done>
    - processSSEStream helper extracts reusable SSE reading logic
    - sendWithRetry includes tools in request body when toolsEnabled
    - Tool calls accumulated from stream and displayed as formatted blocks
    - Tools auto-executed via mcp.executeTool() with results shown
    - Tool results pushed to apiMessages and sent in follow-up request
    - Follow-up requests reuse processSSEStream (no duplicated SSE parsing)
    - Max depth of 3 tool-call rounds prevents infinite loops
    - Depth limit warning shown when reached
    - Auth uses authStore.token directly (no getAuthHeaders import needed)
  </done>
</task>

</tasks>

<verification>
- `cd /Users/atomasini/Development/mlx-manager/frontend && npm run check && npm run lint`
- grep confirms: `processSSEStream` function exists, `MAX_TOOL_DEPTH = 3`, `toolsEnabled`, `mcp.executeTool`, `tool_calls_done`
- No duplicated SSE parsing logic (processSSEStream is the single source)
- No reference to `getAuthHeaders` import (uses authStore.token directly)
</verification>

<success_criteria>
- Tools toggle visible in chat UI when MCP tools are available
- Enabling tools sends tools array to backend in request
- Tool calls from model displayed as formatted blocks in assistant message
- Tool calls auto-executed via mcp.executeTool()
- Tool results sent back to model for continuation
- Multi-round tool use works (model can call tools multiple times)
- Max 3 tool-call rounds enforced with user-visible warning
- No infinite loop possible
- SSE parsing not duplicated (single processSSEStream helper)
- All linting and type checking pass
</success_criteria>

<output>
After completion, create `.planning/phases/06-bug-fixes-stability/06-13-SUMMARY.md`
</output>
